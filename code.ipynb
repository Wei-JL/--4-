{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  比赛页面传送门： 常规赛：[遥感影像地块分割](https://aistudio.baidu.com/aistudio/competition/detail/63)\n",
    "###  欢迎参加飞桨领航团实战速成营 一起学习 ，欢迎一键三连 Fork~\n",
    "###  **赛题介绍：**\n",
    "####  1、 本赛题由 2020 CCF BDCI 遥感影像地块分割 初赛赛题改编而来。遥感影像地块分割, 旨在对遥感影像进行像素级内容解析，对遥感影像中感兴趣的类别进行提取和分类，在城乡规划、防汛救灾等领域具有很高的实用价值，在工业界也受到了广泛关注。现有的遥感影像地块分割数据处理方法局限于特定的场景和特定的数据来源，且精度无法满足需求。因此在实际应用中，仍然大量依赖于人工处理，需要消耗大量的人力、物力、财力。本赛题旨在衡量遥感影像地块分割模型在多个类别（如建筑、耕地、林地等）上的效果，利用人工智能技术，对多来源、多场景的异构遥感影像数据进行充分挖掘，打造高效、实用的算法，提高遥感影像的分析提取能力。 赛题任务 本赛题旨在对遥感影像进行像素级内容解析，并对遥感影像中感兴趣的类别进行提取和分类，以衡量遥感影像地块分割模型在多个类别（如建筑、耕地、林地等）上的效果。\n",
    "\n",
    "### 2、  数据说明\n",
    "#### 本赛题提供了多个地区已脱敏的遥感影像数据，各参赛选手可以基于这些数据构建自己的地块分割模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 训练数据集文件名称：train_and_label.zip\n",
    "\n",
    "## 包含2个子文件，分别为：训练数据集（原始图片）文件、训练数据集（标注图片）文件，详细介绍如下：\n",
    "\n",
    "* **训练数据集**（原始图片）文件名称：img_train\n",
    "\n",
    "包含66,653张分辨率为2m/pixel，尺寸为256 * 256的JPG图片，每张图片的名称形如T000123.jpg。\n",
    "\n",
    "* **训练数据集**（标注图片）文件名称：lab_train\n",
    "\n",
    "包含66,653张分辨率为2m/pixel，尺寸为256 * 256的PNG图片，每张图片的名称形如T000123.png。\n",
    "\n",
    "备注： 全部PNG图片共包括4种分类，像素值分别为0、1、2、3。此外，像素值255为未标注区域，表示对应区域的所属类别并不确定，在评测中也不会考虑这部分区域。\n",
    "\n",
    "* **测试数据集**\n",
    "测试数据集文件名称：img_test.zip，详细介绍如下：\n",
    "\n",
    "包含4,609张分辨率为2m/pixel，尺寸为256 * 256的JPG图片，文件名称形如123.jpg。、\n",
    "\n",
    "## 数据增强工具\n",
    "**PaTTA:** 由第三方开发者组织AgentMaker维护的Test-Time Augmentation库，可在测试时通过数据增强方式产生额外的推理结果，在此基础上进行投票即可获得更稳定的成绩表现。 https://github.com/AgentMaker/PaTTA\n",
    "\n",
    "**RIFLE:** 由第三方开发者对ICML 2020中的《RIFLE: Backpropagation in Depth for Deep Transfer Learning through Re-Initializing the Fully-connected LayEr》论文所提供的封装版本，其通过对输出层多次重新初始化来使得深层backbone得到更充分的更新。 https://github.com/GT-ZhangAcer/RIFLE_Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Requirement already satisfied: paddlex in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.3.8)\n",
      "Requirement already satisfied: sklearn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (0.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (0.4.4)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (4.1.1.26)\n",
      "Requirement already satisfied: flask-cors in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (3.0.8)\n",
      "Requirement already satisfied: paddleslim==1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (1.1.1)\n",
      "Requirement already satisfied: shapely>=1.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (1.7.1)\n",
      "Requirement already satisfied: paddlehub==2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (4.36.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (5.7.2)\n",
      "Requirement already satisfied: visualdl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (2.1.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (5.1.2)\n",
      "Requirement already satisfied: pycocotools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (2.0.2)\n",
      "Requirement already satisfied: xlwt in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (1.20.2)\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (4.1.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (20.9)\n",
      "Requirement already satisfied: paddlenlp>=2.0.0b2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (2.0.0rc7)\n",
      "Requirement already satisfied: flask>=1.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (1.1.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (2.2.3)\n",
      "Requirement already satisfied: rarfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (3.1)\n",
      "Requirement already satisfied: easydict in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (1.9)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (7.1.2)\n",
      "Requirement already satisfied: gunicorn>=19.10.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (20.0.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (3.0.12)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (18.1.1)\n",
      "Requirement already satisfied: gitpython in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.0.1->paddlex) (3.1.14)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==2.0.1->paddlex) (2.10.1)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==2.0.1->paddlex) (0.16.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==2.0.1->paddlex) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==2.0.1->paddlex) (1.1.0)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gunicorn>=19.10.0->paddlehub==2.0.1->paddlex) (56.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.0->paddlehub==2.0.1->paddlex) (1.1.1)\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0b2->paddlehub==2.0.1->paddlex) (0.42.1)\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0b2->paddlehub==2.0.1->paddlex) (1.2.2)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0b2->paddlehub==2.0.1->paddlex) (2.9.0)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (1.0.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (2.22.0)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (0.7.1.1)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (3.14.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (1.15.0)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (3.8.2)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (0.8.53)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex) (1.21.0)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex) (2.6.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex) (0.23)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex) (0.6.1)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex) (2.2.0)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddlex) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddlex) (2019.3)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddlex) (0.18.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddlex) (3.9.9)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gitpython->paddlehub==2.0.1->paddlex) (4.0.5)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython->paddlehub==2.0.1->paddlex) (3.0.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->flake8>=3.7.9->visualdl>=2.0.0->paddlex) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata->flake8>=3.7.9->visualdl>=2.0.0->paddlex) (7.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddlehub==2.0.1->paddlex) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddlehub==2.0.1->paddlex) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddlehub==2.0.1->paddlex) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddlehub==2.0.1->paddlex) (2.8.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex) (2.0.1)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex) (0.10.0)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex) (1.3.0)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex) (16.7.9)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex) (1.3.4)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex) (1.4.10)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pycocotools->paddlex) (0.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex) (3.0.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp>=2.0.0b2->paddlehub==2.0.1->paddlex) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp>=2.0.0b2->paddlehub==2.0.1->paddlex) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp>=2.0.0b2->paddlehub==2.0.1->paddlex) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp>=2.0.0b2->paddlehub==2.0.1->paddlex) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Requirement already satisfied: imgaug in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (7.1.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.20.2)\n",
      "Requirement already satisfied: Shapely in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.7.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.6.2)\n",
      "Requirement already satisfied: imageio in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (2.6.1)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.15.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (4.1.1.26)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (0.18.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (2.2.3)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (2.4)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (2019.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (0.10.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (56.0.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug) (4.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install paddlex -i https://mirror.baidu.com/pypi/simple\r\n",
    "!pip install imgaug -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "# 导入包\r\n",
    "import matplotlib\r\n",
    "import os\r\n",
    "import paddlex as pdx\r\n",
    "import paddle.fluid as fluid # paddle深度学习框架包中的一个模块\r\n",
    "import imgaug.augmenters as iaa\r\n",
    "import numpy as np\r\n",
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\r\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlex.seg import transforms  # 语义分割\r\n",
    "# 图像预处理和增强https://blog.csdn.net/weixin_43593330/article/details/107206239\r\n",
    "train_transforms = transforms.Compose([\r\n",
    "    transforms.RandomHorizontalFlip(),   # 以一定概率对图像进行水平翻转，参数prob（float）：随机水平翻转概率，默认0.5\r\n",
    "    transforms.Resize(target_size=256),  # 调整图像大小\r\n",
    "    # transforms.RandomPaddingCrop(crop_size=256),  # 随机裁剪，当所需要的裁剪尺寸大于原图，则进行padding操作\r\n",
    "    transforms.RandomBlur(prob=0.1),  # 以一定概率对图像进行高斯模糊，参数prob（float）：图像模糊概率，默认0.1\r\n",
    "    transforms.RandomRotate(rotate_range=15),  # 对图像进行随机旋转，当存在标注图像时，同步进行，并对旋转后的图像进行padding\r\n",
    "    # transforms.RandomDistort(brightness_range=0.5),  # 以一定概率对图像进行随机像素内容变换，该方法必须在Normalize之前使用\r\n",
    "    transforms.Normalize()  # 归一化\r\n",
    "])\r\n",
    "eval_transforms = transforms.Compose([\r\n",
    "    transforms.Resize(256),\r\n",
    "    transforms.Normalize()\r\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据集的解压\r\n",
    "# !unzip data/data81053/img_test.zip\r\n",
    "# !unzip data/data81053/train_and_label.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 66652\n",
      "img_train/T094090.jpg\n",
      "lab_train/T094090.png\n"
     ]
    }
   ],
   "source": [
    "datas = []\r\n",
    "# 定义训练图片和标签\r\n",
    "image_base = 'img_train'\r\n",
    "annos_base = 'lab_train'\r\n",
    "# os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表。这个列表以字母顺序。 它不包括 '.' 和'..' 即使它在文件夹中\r\n",
    "ids_ = [v.split('.')[0] for v in os.listdir(image_base)]\r\n",
    "\r\n",
    "for id_ in ids_:\r\n",
    "    img_pt0 = os.path.join(image_base, '{}.jpg'.format(id_))  # os.path.join() 方法把目录和文件名合成一个路径\r\n",
    "    img_pt1 = os.path.join(annos_base, '{}.png'.format(id_))\r\n",
    "    datas.append((img_pt0.replace('/home/aistudio/work/', ''), img_pt1.replace('/home/aistudio/work/', '')))  # 将 img_pt0和 img_pt1连接\r\n",
    "    if os.path.exists(img_pt0) and os.path.exists(img_pt1):  # os.path.exists（）路径存在则返回True,路径损坏返回False\r\n",
    "        pass\r\n",
    "    else:\r\n",
    "        raise \"path invalid!\"\r\n",
    "\r\n",
    "print('total:', len(datas))\r\n",
    "print(datas[0][0])\r\n",
    "print(datas[0][1])\r\n",
    "\r\n",
    "data_dir = '/home/aistudio/work/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 65986\n",
      "valid: 666\n"
     ]
    }
   ],
   "source": [
    "# 给图像标签赋予含义\r\n",
    "labels = [\r\n",
    "    '建筑', '耕地', '林地',\r\n",
    "    '其他'\r\n",
    "]\r\n",
    "# 标签写入labels.txt文件\r\n",
    "with open('labels.txt', 'w') as f:\r\n",
    "    for v in labels:\r\n",
    "        f.write(v+'\\n')\r\n",
    "# 将数据进行打乱\r\n",
    "np.random.seed(5)\r\n",
    "np.random.shuffle(datas)\r\n",
    "# 将数据划分为训练集和测试集\r\n",
    "split_num = int(0.01*len(datas))\r\n",
    "\r\n",
    "train_data = datas[:-split_num]\r\n",
    "valid_data = datas[-split_num:]\r\n",
    "# 将训练集写入train_list.txt\r\n",
    "with open('train_list.txt', 'w') as f:\r\n",
    "    for img, lbl in train_data:\r\n",
    "        f.write(img + ' ' + lbl + '\\n')\r\n",
    "# 将测试集写入valid_list.txt\r\n",
    "with open('valid_list.txt', 'w') as f:\r\n",
    "    for img, lbl in valid_data:\r\n",
    "        f.write(img + ' ' + lbl + '\\n')\r\n",
    "\r\n",
    "print('train:', len(train_data))\r\n",
    "print('valid:', len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 23:09:37 [INFO]\t65986 samples in file train_list.txt\n",
      "2021-05-05 23:09:37 [INFO]\t666 samples in file valid_list.txt\n"
     ]
    }
   ],
   "source": [
    "data_dir = './'\r\n",
    "# paddlex.datasets的说明文档百度：https://paddlex.readthedocs.io/zh_CN/develop/apis/datasets.html  \r\n",
    "# paddlex.datasets.SegDataset()用于语义分割模型\r\n",
    "train_dataset = pdx.datasets.SegDataset(\r\n",
    "    data_dir=data_dir,  # 数据集路径\r\n",
    "    file_list='train_list.txt',  # 描述数据集图片文件和对应标注文件的文件路径\r\n",
    "    label_list='labels.txt',  # 描述数据集包含的类别信息文件路径\r\n",
    "    transforms=train_transforms,  # 数据集中每个样本的预处理/增强算子\r\n",
    "    shuffle=True)  #是否需要对数据集中样本打乱顺序。默认为False\r\n",
    "    \r\n",
    "eval_dataset = pdx.datasets.SegDataset(\r\n",
    "    data_dir=data_dir,\r\n",
    "    file_list='valid_list.txt',\r\n",
    "    label_list='labels.txt',\r\n",
    "    transforms=eval_transforms)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/xception.py:316\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py:687: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  elif dtype == np.bool:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/segmentation/model_utils/loss.py:74\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle2onnx/onnx_helper/mapping.py:42: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  int(TensorProto.STRING): np.dtype(np.object)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle2onnx/constant/dtypes.py:43: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: core.VarDesc.VarType.BOOL,\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle2onnx/constant/dtypes.py:44: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  core.VarDesc.VarType.FP32: np.float,\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle2onnx/constant/dtypes.py:49: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  core.VarDesc.VarType.BOOL: np.bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 23:09:44 [INFO]\tConnecting PaddleHub server to get pretrain weights...\n",
      "2021-05-05 23:09:49 [INFO]\tLoad pretrain weights from output/deeplab/pretrain/DeepLabv3p_Xception65_COCO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/executor.py:1150: UserWarning: There are no operators in the program to be executed. If you pass Program manually, please use fluid.program_guard to ensure the current Program is being used.\n",
      "  warnings.warn(error_info)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 23:09:49 [WARNING]\tThere is no pretrain weights loaded, maybe you should check you pretrain model!\n",
      "2021-05-05 23:10:55 [INFO]\t[TRAIN] Epoch=1/40, Step=200/4124, loss=1.56313, time_each_step=0.3s, eta=13:46:48\n",
      "2021-05-05 23:11:56 [INFO]\t[TRAIN] Epoch=1/40, Step=400/4124, loss=1.414656, time_each_step=0.3s, eta=13:58:37\n",
      "2021-05-05 23:12:56 [INFO]\t[TRAIN] Epoch=1/40, Step=600/4124, loss=1.291021, time_each_step=0.3s, eta=13:57:17\n",
      "2021-05-05 23:13:57 [INFO]\t[TRAIN] Epoch=1/40, Step=800/4124, loss=1.242409, time_each_step=0.31s, eta=14:0:47\n",
      "2021-05-05 23:14:57 [INFO]\t[TRAIN] Epoch=1/40, Step=1000/4124, loss=1.438219, time_each_step=0.3s, eta=13:53:46\n",
      "2021-05-05 23:15:58 [INFO]\t[TRAIN] Epoch=1/40, Step=1200/4124, loss=1.559485, time_each_step=0.3s, eta=13:49:25\n",
      "2021-05-05 23:16:59 [INFO]\t[TRAIN] Epoch=1/40, Step=1400/4124, loss=1.135852, time_each_step=0.3s, eta=13:48:7\n",
      "2021-05-05 23:18:00 [INFO]\t[TRAIN] Epoch=1/40, Step=1600/4124, loss=0.734391, time_each_step=0.31s, eta=14:5:32\n",
      "2021-05-05 23:19:00 [INFO]\t[TRAIN] Epoch=1/40, Step=1800/4124, loss=1.539115, time_each_step=0.3s, eta=13:47:9\n",
      "2021-05-05 23:20:01 [INFO]\t[TRAIN] Epoch=1/40, Step=2000/4124, loss=1.092326, time_each_step=0.3s, eta=13:43:3\n",
      "2021-05-05 23:21:02 [INFO]\t[TRAIN] Epoch=1/40, Step=2200/4124, loss=0.930696, time_each_step=0.3s, eta=13:47:9\n",
      "2021-05-05 23:22:03 [INFO]\t[TRAIN] Epoch=1/40, Step=2400/4124, loss=0.753186, time_each_step=0.3s, eta=13:43:28\n",
      "2021-05-05 23:23:04 [INFO]\t[TRAIN] Epoch=1/40, Step=2600/4124, loss=1.360949, time_each_step=0.31s, eta=13:54:49\n",
      "2021-05-05 23:24:04 [INFO]\t[TRAIN] Epoch=1/40, Step=2800/4124, loss=1.062406, time_each_step=0.31s, eta=13:49:37\n",
      "2021-05-05 23:25:05 [INFO]\t[TRAIN] Epoch=1/40, Step=3000/4124, loss=1.221865, time_each_step=0.3s, eta=13:45:37\n",
      "2021-05-05 23:26:06 [INFO]\t[TRAIN] Epoch=1/40, Step=3200/4124, loss=1.069869, time_each_step=0.3s, eta=13:34:20\n",
      "2021-05-05 23:27:07 [INFO]\t[TRAIN] Epoch=1/40, Step=3400/4124, loss=0.836953, time_each_step=0.3s, eta=13:39:32\n",
      "2021-05-05 23:28:08 [INFO]\t[TRAIN] Epoch=1/40, Step=3600/4124, loss=1.243854, time_each_step=0.3s, eta=13:44:25\n",
      "2021-05-05 23:29:09 [INFO]\t[TRAIN] Epoch=1/40, Step=3800/4124, loss=0.833245, time_each_step=0.3s, eta=13:39:25\n",
      "2021-05-05 23:30:10 [INFO]\t[TRAIN] Epoch=1/40, Step=4000/4124, loss=0.94347, time_each_step=0.3s, eta=13:30:41\n",
      "2021-05-05 23:30:47 [INFO]\t[TRAIN] Epoch 1 finished, loss=1.125084 .\n",
      "2021-05-05 23:31:14 [INFO]\t[TRAIN] Epoch=2/40, Step=76/4124, loss=0.948958, time_each_step=0.3s, eta=13:41:28\n",
      "2021-05-05 23:32:15 [INFO]\t[TRAIN] Epoch=2/40, Step=276/4124, loss=1.147842, time_each_step=0.3s, eta=13:40:22\n",
      "2021-05-05 23:33:16 [INFO]\t[TRAIN] Epoch=2/40, Step=476/4124, loss=0.970372, time_each_step=0.3s, eta=13:39:29\n",
      "2021-05-05 23:34:17 [INFO]\t[TRAIN] Epoch=2/40, Step=676/4124, loss=0.955662, time_each_step=0.3s, eta=13:38:20\n",
      "2021-05-05 23:35:17 [INFO]\t[TRAIN] Epoch=2/40, Step=876/4124, loss=1.376627, time_each_step=0.3s, eta=13:37:9\n",
      "2021-05-05 23:36:18 [INFO]\t[TRAIN] Epoch=2/40, Step=1076/4124, loss=1.039183, time_each_step=0.3s, eta=13:36:16\n",
      "2021-05-05 23:37:18 [INFO]\t[TRAIN] Epoch=2/40, Step=1276/4124, loss=0.970426, time_each_step=0.3s, eta=13:35:15\n",
      "2021-05-05 23:38:19 [INFO]\t[TRAIN] Epoch=2/40, Step=1476/4124, loss=1.258678, time_each_step=0.3s, eta=13:34:18\n",
      "2021-05-05 23:39:20 [INFO]\t[TRAIN] Epoch=2/40, Step=1676/4124, loss=0.965215, time_each_step=0.3s, eta=13:33:18\n",
      "2021-05-05 23:40:21 [INFO]\t[TRAIN] Epoch=2/40, Step=1876/4124, loss=0.756117, time_each_step=0.3s, eta=13:32:15\n",
      "2021-05-05 23:41:21 [INFO]\t[TRAIN] Epoch=2/40, Step=2076/4124, loss=0.977756, time_each_step=0.3s, eta=13:31:19\n",
      "2021-05-05 23:42:22 [INFO]\t[TRAIN] Epoch=2/40, Step=2276/4124, loss=1.191827, time_each_step=0.3s, eta=13:30:17\n",
      "2021-05-05 23:43:22 [INFO]\t[TRAIN] Epoch=2/40, Step=2476/4124, loss=0.89864, time_each_step=0.3s, eta=13:29:16\n",
      "2021-05-05 23:44:23 [INFO]\t[TRAIN] Epoch=2/40, Step=2676/4124, loss=1.070635, time_each_step=0.3s, eta=13:28:17\n",
      "2021-05-05 23:45:24 [INFO]\t[TRAIN] Epoch=2/40, Step=2876/4124, loss=0.805845, time_each_step=0.31s, eta=13:27:21\n",
      "2021-05-05 23:46:25 [INFO]\t[TRAIN] Epoch=2/40, Step=3076/4124, loss=0.818136, time_each_step=0.3s, eta=13:26:16\n",
      "2021-05-05 23:47:25 [INFO]\t[TRAIN] Epoch=2/40, Step=3276/4124, loss=1.100554, time_each_step=0.3s, eta=13:25:15\n",
      "2021-05-05 23:48:26 [INFO]\t[TRAIN] Epoch=2/40, Step=3476/4124, loss=0.956421, time_each_step=0.3s, eta=13:24:14\n",
      "2021-05-05 23:49:27 [INFO]\t[TRAIN] Epoch=2/40, Step=3676/4124, loss=1.235822, time_each_step=0.3s, eta=13:23:13\n",
      "2021-05-05 23:50:28 [INFO]\t[TRAIN] Epoch=2/40, Step=3876/4124, loss=0.853034, time_each_step=0.3s, eta=13:22:14\n",
      "2021-05-05 23:51:28 [INFO]\t[TRAIN] Epoch=2/40, Step=4076/4124, loss=0.789268, time_each_step=0.3s, eta=13:21:11\n",
      "2021-05-05 23:51:43 [INFO]\t[TRAIN] Epoch 2 finished, loss=1.006899 .\n",
      "2021-05-05 23:51:43 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]share_vars_from is set, scope is ignored.\n",
      "100%|██████████| 42/42 [00:07<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-05 23:51:50 [INFO]\t[EVAL] Finished, Epoch=2, miou=0.294695, category_iou=[0.37549017 0.49232627 0.26694707 0.04401743], oacc=0.497194, category_acc=[0.45752845 0.78886336 0.33609183 0.45507103], kappa=0.310496, category_F1-score=[0.54597289 0.6598105  0.42140208 0.08432317] .\n",
      "2021-05-05 23:51:54 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-05-05 23:51:57 [INFO]\tModel saved in output/deeplab/epoch_2.\n",
      "2021-05-05 23:51:57 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_2, miou=0.29469523391556907\n",
      "2021-05-05 23:52:46 [INFO]\t[TRAIN] Epoch=3/40, Step=152/4124, loss=1.364012, time_each_step=0.3s, eta=13:18:58\n",
      "2021-05-05 23:53:47 [INFO]\t[TRAIN] Epoch=3/40, Step=352/4124, loss=0.815342, time_each_step=0.31s, eta=13:18:2\n",
      "2021-05-05 23:54:48 [INFO]\t[TRAIN] Epoch=3/40, Step=552/4124, loss=0.575706, time_each_step=0.3s, eta=13:16:59\n",
      "2021-05-05 23:55:48 [INFO]\t[TRAIN] Epoch=3/40, Step=752/4124, loss=0.685946, time_each_step=0.3s, eta=13:15:51\n",
      "2021-05-05 23:56:49 [INFO]\t[TRAIN] Epoch=3/40, Step=952/4124, loss=0.776617, time_each_step=0.3s, eta=13:14:49\n",
      "2021-05-05 23:57:50 [INFO]\t[TRAIN] Epoch=3/40, Step=1152/4124, loss=0.863396, time_each_step=0.3s, eta=13:13:51\n",
      "2021-05-05 23:58:50 [INFO]\t[TRAIN] Epoch=3/40, Step=1352/4124, loss=0.776646, time_each_step=0.3s, eta=13:12:48\n",
      "2021-05-05 23:59:51 [INFO]\t[TRAIN] Epoch=3/40, Step=1552/4124, loss=0.689287, time_each_step=0.3s, eta=13:11:50\n",
      "2021-05-06 00:00:52 [INFO]\t[TRAIN] Epoch=3/40, Step=1752/4124, loss=0.990514, time_each_step=0.31s, eta=13:11:0\n",
      "2021-05-06 00:01:53 [INFO]\t[TRAIN] Epoch=3/40, Step=1952/4124, loss=0.895189, time_each_step=0.3s, eta=13:9:45\n",
      "2021-05-06 00:02:54 [INFO]\t[TRAIN] Epoch=3/40, Step=2152/4124, loss=1.192931, time_each_step=0.3s, eta=13:8:45\n",
      "2021-05-06 00:03:54 [INFO]\t[TRAIN] Epoch=3/40, Step=2352/4124, loss=1.015492, time_each_step=0.3s, eta=13:7:47\n",
      "2021-05-06 00:04:55 [INFO]\t[TRAIN] Epoch=3/40, Step=2552/4124, loss=0.829413, time_each_step=0.3s, eta=13:6:46\n",
      "2021-05-06 00:05:56 [INFO]\t[TRAIN] Epoch=3/40, Step=2752/4124, loss=0.720275, time_each_step=0.3s, eta=13:5:46\n",
      "2021-05-06 00:06:57 [INFO]\t[TRAIN] Epoch=3/40, Step=2952/4124, loss=1.3159, time_each_step=0.3s, eta=13:4:45\n",
      "2021-05-06 00:07:57 [INFO]\t[TRAIN] Epoch=3/40, Step=3152/4124, loss=0.78833, time_each_step=0.3s, eta=13:3:45\n",
      "2021-05-06 00:08:58 [INFO]\t[TRAIN] Epoch=3/40, Step=3352/4124, loss=0.991823, time_each_step=0.3s, eta=13:2:44\n",
      "2021-05-06 00:09:59 [INFO]\t[TRAIN] Epoch=3/40, Step=3552/4124, loss=0.67879, time_each_step=0.3s, eta=13:1:43\n",
      "2021-05-06 00:11:00 [INFO]\t[TRAIN] Epoch=3/40, Step=3752/4124, loss=1.098528, time_each_step=0.3s, eta=13:0:43\n",
      "2021-05-06 00:12:01 [INFO]\t[TRAIN] Epoch=3/40, Step=3952/4124, loss=0.619197, time_each_step=0.3s, eta=12:59:42\n",
      "2021-05-06 00:12:53 [INFO]\t[TRAIN] Epoch 3 finished, loss=0.952991 .\n",
      "2021-05-06 00:13:06 [INFO]\t[TRAIN] Epoch=4/40, Step=28/4124, loss=0.87715, time_each_step=0.33s, eta=13:0:15\n",
      "2021-05-06 00:14:07 [INFO]\t[TRAIN] Epoch=4/40, Step=228/4124, loss=1.327357, time_each_step=0.3s, eta=12:57:31\n",
      "2021-05-06 00:15:07 [INFO]\t[TRAIN] Epoch=4/40, Step=428/4124, loss=0.763173, time_each_step=0.3s, eta=12:56:29\n",
      "2021-05-06 00:16:08 [INFO]\t[TRAIN] Epoch=4/40, Step=628/4124, loss=0.659259, time_each_step=0.3s, eta=12:55:35\n",
      "2021-05-06 00:17:09 [INFO]\t[TRAIN] Epoch=4/40, Step=828/4124, loss=0.960896, time_each_step=0.3s, eta=12:54:35\n",
      "2021-05-06 00:18:10 [INFO]\t[TRAIN] Epoch=4/40, Step=1028/4124, loss=0.827852, time_each_step=0.3s, eta=12:53:34\n",
      "2021-05-06 00:19:10 [INFO]\t[TRAIN] Epoch=4/40, Step=1228/4124, loss=0.77919, time_each_step=0.3s, eta=12:52:33\n",
      "2021-05-06 00:20:12 [INFO]\t[TRAIN] Epoch=4/40, Step=1428/4124, loss=1.343902, time_each_step=0.31s, eta=12:51:42\n",
      "2021-05-06 00:21:12 [INFO]\t[TRAIN] Epoch=4/40, Step=1628/4124, loss=0.654377, time_each_step=0.31s, eta=12:50:52\n",
      "2021-05-06 00:22:13 [INFO]\t[TRAIN] Epoch=4/40, Step=1828/4124, loss=1.022807, time_each_step=0.3s, eta=12:49:31\n",
      "2021-05-06 00:23:14 [INFO]\t[TRAIN] Epoch=4/40, Step=2028/4124, loss=1.154443, time_each_step=0.3s, eta=12:48:31\n",
      "2021-05-06 00:24:15 [INFO]\t[TRAIN] Epoch=4/40, Step=2228/4124, loss=0.723405, time_each_step=0.3s, eta=12:47:31\n",
      "2021-05-06 00:25:16 [INFO]\t[TRAIN] Epoch=4/40, Step=2428/4124, loss=0.520585, time_each_step=0.3s, eta=12:46:23\n",
      "2021-05-06 00:26:16 [INFO]\t[TRAIN] Epoch=4/40, Step=2628/4124, loss=0.718626, time_each_step=0.3s, eta=12:45:29\n",
      "2021-05-06 00:27:17 [INFO]\t[TRAIN] Epoch=4/40, Step=2828/4124, loss=1.674475, time_each_step=0.3s, eta=12:44:26\n",
      "2021-05-06 00:28:18 [INFO]\t[TRAIN] Epoch=4/40, Step=3028/4124, loss=0.821212, time_each_step=0.31s, eta=12:43:28\n",
      "2021-05-06 00:29:19 [INFO]\t[TRAIN] Epoch=4/40, Step=3228/4124, loss=0.884447, time_each_step=0.3s, eta=12:42:25\n",
      "2021-05-06 00:30:20 [INFO]\t[TRAIN] Epoch=4/40, Step=3428/4124, loss=1.169225, time_each_step=0.3s, eta=12:41:26\n",
      "2021-05-06 00:31:21 [INFO]\t[TRAIN] Epoch=4/40, Step=3628/4124, loss=0.956377, time_each_step=0.3s, eta=12:40:25\n",
      "2021-05-06 00:32:21 [INFO]\t[TRAIN] Epoch=4/40, Step=3828/4124, loss=0.929922, time_each_step=0.3s, eta=12:39:24\n",
      "2021-05-06 00:33:22 [INFO]\t[TRAIN] Epoch=4/40, Step=4028/4124, loss=0.834323, time_each_step=0.3s, eta=12:38:23\n",
      "2021-05-06 00:33:51 [INFO]\t[TRAIN] Epoch 4 finished, loss=0.922388 .\n",
      "2021-05-06 00:33:51 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 00:33:58 [INFO]\t[EVAL] Finished, Epoch=4, miou=0.383049, category_iou=[0.39181288 0.59672348 0.32897113 0.21468714], oacc=0.579016, category_acc=[0.48353301 0.73723441 0.57946319 0.4949008 ], kappa=0.412649, category_F1-score=[0.56302522 0.74743497 0.49507641 0.35348549] .\n",
      "2021-05-06 00:34:02 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-05-06 00:34:05 [INFO]\tModel saved in output/deeplab/epoch_4.\n",
      "2021-05-06 00:34:05 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_4, miou=0.3830486558668278\n",
      "2021-05-06 00:34:41 [INFO]\t[TRAIN] Epoch=5/40, Step=104/4124, loss=1.008366, time_each_step=0.3s, eta=12:38:44\n",
      "2021-05-06 00:35:41 [INFO]\t[TRAIN] Epoch=5/40, Step=304/4124, loss=1.253357, time_each_step=0.3s, eta=12:37:46\n",
      "2021-05-06 00:36:42 [INFO]\t[TRAIN] Epoch=5/40, Step=504/4124, loss=1.107406, time_each_step=0.3s, eta=12:36:28\n",
      "2021-05-06 00:37:43 [INFO]\t[TRAIN] Epoch=5/40, Step=704/4124, loss=0.709004, time_each_step=0.3s, eta=12:35:43\n",
      "2021-05-06 00:38:43 [INFO]\t[TRAIN] Epoch=5/40, Step=904/4124, loss=1.014553, time_each_step=0.3s, eta=12:34:37\n",
      "2021-05-06 00:39:44 [INFO]\t[TRAIN] Epoch=5/40, Step=1104/4124, loss=1.181589, time_each_step=0.3s, eta=12:33:37\n",
      "2021-05-06 00:40:45 [INFO]\t[TRAIN] Epoch=5/40, Step=1304/4124, loss=0.561624, time_each_step=0.3s, eta=12:32:38\n",
      "2021-05-06 00:41:46 [INFO]\t[TRAIN] Epoch=5/40, Step=1504/4124, loss=1.182974, time_each_step=0.31s, eta=12:31:52\n",
      "2021-05-06 00:42:47 [INFO]\t[TRAIN] Epoch=5/40, Step=1704/4124, loss=0.759225, time_each_step=0.31s, eta=12:30:49\n",
      "2021-05-06 00:43:48 [INFO]\t[TRAIN] Epoch=5/40, Step=1904/4124, loss=0.963659, time_each_step=0.3s, eta=12:29:38\n",
      "2021-05-06 00:44:48 [INFO]\t[TRAIN] Epoch=5/40, Step=2104/4124, loss=0.964141, time_each_step=0.3s, eta=12:28:35\n",
      "2021-05-06 00:45:49 [INFO]\t[TRAIN] Epoch=5/40, Step=2304/4124, loss=0.826565, time_each_step=0.31s, eta=12:27:38\n",
      "2021-05-06 00:46:50 [INFO]\t[TRAIN] Epoch=5/40, Step=2504/4124, loss=0.592713, time_each_step=0.3s, eta=12:26:35\n",
      "2021-05-06 00:47:51 [INFO]\t[TRAIN] Epoch=5/40, Step=2704/4124, loss=0.910674, time_each_step=0.3s, eta=12:25:31\n",
      "2021-05-06 00:48:51 [INFO]\t[TRAIN] Epoch=5/40, Step=2904/4124, loss=0.628438, time_each_step=0.31s, eta=12:24:34\n",
      "2021-05-06 00:49:52 [INFO]\t[TRAIN] Epoch=5/40, Step=3104/4124, loss=0.874093, time_each_step=0.3s, eta=12:23:28\n",
      "2021-05-06 00:50:53 [INFO]\t[TRAIN] Epoch=5/40, Step=3304/4124, loss=0.710404, time_each_step=0.3s, eta=12:22:31\n",
      "2021-05-06 00:51:54 [INFO]\t[TRAIN] Epoch=5/40, Step=3504/4124, loss=0.943865, time_each_step=0.3s, eta=12:21:31\n",
      "2021-05-06 00:52:55 [INFO]\t[TRAIN] Epoch=5/40, Step=3704/4124, loss=0.905204, time_each_step=0.3s, eta=12:20:29\n",
      "2021-05-06 00:53:55 [INFO]\t[TRAIN] Epoch=5/40, Step=3904/4124, loss=0.859698, time_each_step=0.3s, eta=12:19:28\n",
      "2021-05-06 00:54:56 [INFO]\t[TRAIN] Epoch=5/40, Step=4104/4124, loss=0.798158, time_each_step=0.3s, eta=12:18:28\n",
      "2021-05-06 00:55:02 [INFO]\t[TRAIN] Epoch 5 finished, loss=0.898285 .\n",
      "2021-05-06 00:56:02 [INFO]\t[TRAIN] Epoch=6/40, Step=180/4124, loss=0.774669, time_each_step=0.3s, eta=12:16:22\n",
      "2021-05-06 00:57:02 [INFO]\t[TRAIN] Epoch=6/40, Step=380/4124, loss=0.777096, time_each_step=0.31s, eta=12:15:36\n",
      "2021-05-06 00:58:03 [INFO]\t[TRAIN] Epoch=6/40, Step=580/4124, loss=0.808331, time_each_step=0.32s, eta=12:15:2\n",
      "2021-05-06 00:59:04 [INFO]\t[TRAIN] Epoch=6/40, Step=780/4124, loss=0.823997, time_each_step=0.31s, eta=12:13:26\n",
      "2021-05-06 01:00:05 [INFO]\t[TRAIN] Epoch=6/40, Step=980/4124, loss=0.682808, time_each_step=0.3s, eta=12:12:17\n",
      "2021-05-06 01:01:06 [INFO]\t[TRAIN] Epoch=6/40, Step=1180/4124, loss=0.667858, time_each_step=0.3s, eta=12:11:17\n",
      "2021-05-06 01:02:07 [INFO]\t[TRAIN] Epoch=6/40, Step=1380/4124, loss=1.095351, time_each_step=0.3s, eta=12:10:16\n",
      "2021-05-06 01:03:08 [INFO]\t[TRAIN] Epoch=6/40, Step=1580/4124, loss=0.978636, time_each_step=0.3s, eta=12:9:18\n",
      "2021-05-06 01:04:09 [INFO]\t[TRAIN] Epoch=6/40, Step=1780/4124, loss=0.864768, time_each_step=0.3s, eta=12:8:20\n",
      "2021-05-06 01:05:10 [INFO]\t[TRAIN] Epoch=6/40, Step=1980/4124, loss=1.026269, time_each_step=0.3s, eta=12:7:7\n",
      "2021-05-06 01:06:10 [INFO]\t[TRAIN] Epoch=6/40, Step=2180/4124, loss=0.838113, time_each_step=0.3s, eta=12:6:16\n",
      "2021-05-06 01:07:11 [INFO]\t[TRAIN] Epoch=6/40, Step=2380/4124, loss=0.788155, time_each_step=0.3s, eta=12:5:12\n",
      "2021-05-06 01:08:12 [INFO]\t[TRAIN] Epoch=6/40, Step=2580/4124, loss=0.819025, time_each_step=0.31s, eta=12:4:16\n",
      "2021-05-06 01:09:13 [INFO]\t[TRAIN] Epoch=6/40, Step=2780/4124, loss=0.834069, time_each_step=0.3s, eta=12:3:14\n",
      "2021-05-06 01:10:14 [INFO]\t[TRAIN] Epoch=6/40, Step=2980/4124, loss=1.07883, time_each_step=0.3s, eta=12:2:12\n",
      "2021-05-06 01:11:15 [INFO]\t[TRAIN] Epoch=6/40, Step=3180/4124, loss=0.717698, time_each_step=0.3s, eta=12:1:13\n",
      "2021-05-06 01:12:16 [INFO]\t[TRAIN] Epoch=6/40, Step=3380/4124, loss=0.706562, time_each_step=0.3s, eta=12:0:11\n",
      "2021-05-06 01:13:17 [INFO]\t[TRAIN] Epoch=6/40, Step=3580/4124, loss=0.811263, time_each_step=0.3s, eta=11:59:10\n",
      "2021-05-06 01:14:18 [INFO]\t[TRAIN] Epoch=6/40, Step=3780/4124, loss=0.885151, time_each_step=0.3s, eta=11:58:10\n",
      "2021-05-06 01:15:19 [INFO]\t[TRAIN] Epoch=6/40, Step=3980/4124, loss=0.78138, time_each_step=0.3s, eta=11:57:9\n",
      "2021-05-06 01:16:03 [INFO]\t[TRAIN] Epoch 6 finished, loss=0.881039 .\n",
      "2021-05-06 01:16:03 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:06<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 01:16:10 [INFO]\t[EVAL] Finished, Epoch=6, miou=0.372131, category_iou=[0.3849788  0.53930145 0.31159182 0.25265372], oacc=0.565294, category_acc=[0.48574281 0.69255923 0.51928421 0.5581625 ], kappa=0.395715, category_F1-score=[0.55593458 0.70070934 0.47513535 0.40338956] .\n",
      "2021-05-06 01:16:13 [INFO]\tModel saved in output/deeplab/epoch_6.\n",
      "2021-05-06 01:16:13 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_4, miou=0.3830486558668278\n",
      "2021-05-06 01:16:34 [INFO]\t[TRAIN] Epoch=7/40, Step=56/4124, loss=0.877642, time_each_step=0.31s, eta=11:57:23\n",
      "2021-05-06 01:17:34 [INFO]\t[TRAIN] Epoch=7/40, Step=256/4124, loss=0.655754, time_each_step=0.3s, eta=11:55:48\n",
      "2021-05-06 01:18:35 [INFO]\t[TRAIN] Epoch=7/40, Step=456/4124, loss=1.151856, time_each_step=0.3s, eta=11:54:54\n",
      "2021-05-06 01:19:36 [INFO]\t[TRAIN] Epoch=7/40, Step=656/4124, loss=0.711081, time_each_step=0.3s, eta=11:53:45\n",
      "2021-05-06 01:20:37 [INFO]\t[TRAIN] Epoch=7/40, Step=856/4124, loss=0.737429, time_each_step=0.3s, eta=11:52:43\n",
      "2021-05-06 01:21:38 [INFO]\t[TRAIN] Epoch=7/40, Step=1056/4124, loss=0.835907, time_each_step=0.3s, eta=11:51:51\n",
      "2021-05-06 01:22:38 [INFO]\t[TRAIN] Epoch=7/40, Step=1256/4124, loss=1.180712, time_each_step=0.3s, eta=11:50:47\n",
      "2021-05-06 01:23:40 [INFO]\t[TRAIN] Epoch=7/40, Step=1456/4124, loss=1.079275, time_each_step=0.3s, eta=11:49:43\n",
      "2021-05-06 01:24:40 [INFO]\t[TRAIN] Epoch=7/40, Step=1656/4124, loss=0.675837, time_each_step=0.3s, eta=11:48:48\n",
      "2021-05-06 01:25:41 [INFO]\t[TRAIN] Epoch=7/40, Step=1856/4124, loss=0.698402, time_each_step=0.31s, eta=11:47:57\n",
      "2021-05-06 01:26:42 [INFO]\t[TRAIN] Epoch=7/40, Step=2056/4124, loss=1.119001, time_each_step=0.3s, eta=11:46:43\n",
      "2021-05-06 01:27:43 [INFO]\t[TRAIN] Epoch=7/40, Step=2256/4124, loss=0.6495, time_each_step=0.3s, eta=11:45:44\n",
      "2021-05-06 01:28:43 [INFO]\t[TRAIN] Epoch=7/40, Step=2456/4124, loss=0.567434, time_each_step=0.3s, eta=11:44:41\n",
      "2021-05-06 01:29:44 [INFO]\t[TRAIN] Epoch=7/40, Step=2656/4124, loss=1.000649, time_each_step=0.3s, eta=11:43:40\n",
      "2021-05-06 01:30:45 [INFO]\t[TRAIN] Epoch=7/40, Step=2856/4124, loss=0.726861, time_each_step=0.3s, eta=11:42:43\n",
      "2021-05-06 01:31:46 [INFO]\t[TRAIN] Epoch=7/40, Step=3056/4124, loss=0.848321, time_each_step=0.3s, eta=11:41:41\n",
      "2021-05-06 01:32:47 [INFO]\t[TRAIN] Epoch=7/40, Step=3256/4124, loss=1.043065, time_each_step=0.31s, eta=11:40:47\n",
      "2021-05-06 01:33:47 [INFO]\t[TRAIN] Epoch=7/40, Step=3456/4124, loss=1.181424, time_each_step=0.31s, eta=11:39:41\n",
      "2021-05-06 01:34:48 [INFO]\t[TRAIN] Epoch=7/40, Step=3656/4124, loss=0.618824, time_each_step=0.31s, eta=11:38:41\n",
      "2021-05-06 01:35:49 [INFO]\t[TRAIN] Epoch=7/40, Step=3856/4124, loss=1.028941, time_each_step=0.3s, eta=11:37:38\n",
      "2021-05-06 01:36:50 [INFO]\t[TRAIN] Epoch=7/40, Step=4056/4124, loss=0.825149, time_each_step=0.3s, eta=11:36:37\n",
      "2021-05-06 01:37:11 [INFO]\t[TRAIN] Epoch 7 finished, loss=0.858972 .\n",
      "2021-05-06 01:37:55 [INFO]\t[TRAIN] Epoch=8/40, Step=132/4124, loss=1.154942, time_each_step=0.31s, eta=11:33:59\n",
      "2021-05-06 01:38:56 [INFO]\t[TRAIN] Epoch=8/40, Step=332/4124, loss=0.576808, time_each_step=0.3s, eta=11:32:48\n",
      "2021-05-06 01:39:57 [INFO]\t[TRAIN] Epoch=8/40, Step=532/4124, loss=0.762157, time_each_step=0.3s, eta=11:31:33\n",
      "2021-05-06 01:40:58 [INFO]\t[TRAIN] Epoch=8/40, Step=732/4124, loss=0.566862, time_each_step=0.3s, eta=11:30:48\n",
      "2021-05-06 01:41:59 [INFO]\t[TRAIN] Epoch=8/40, Step=932/4124, loss=0.78473, time_each_step=0.31s, eta=11:29:57\n",
      "2021-05-06 01:42:59 [INFO]\t[TRAIN] Epoch=8/40, Step=1132/4124, loss=0.769049, time_each_step=0.31s, eta=11:28:56\n",
      "2021-05-06 01:44:00 [INFO]\t[TRAIN] Epoch=8/40, Step=1332/4124, loss=1.330881, time_each_step=0.3s, eta=11:27:44\n",
      "2021-05-06 01:45:01 [INFO]\t[TRAIN] Epoch=8/40, Step=1532/4124, loss=0.612572, time_each_step=0.3s, eta=11:26:44\n",
      "2021-05-06 01:46:02 [INFO]\t[TRAIN] Epoch=8/40, Step=1732/4124, loss=1.121057, time_each_step=0.3s, eta=11:25:43\n",
      "2021-05-06 01:47:03 [INFO]\t[TRAIN] Epoch=8/40, Step=1932/4124, loss=0.77993, time_each_step=0.31s, eta=11:24:47\n",
      "2021-05-06 01:48:04 [INFO]\t[TRAIN] Epoch=8/40, Step=2132/4124, loss=0.89728, time_each_step=0.31s, eta=11:23:57\n",
      "2021-05-06 01:49:05 [INFO]\t[TRAIN] Epoch=8/40, Step=2332/4124, loss=1.399656, time_each_step=0.3s, eta=11:22:40\n",
      "2021-05-06 01:50:06 [INFO]\t[TRAIN] Epoch=8/40, Step=2532/4124, loss=1.067464, time_each_step=0.3s, eta=11:21:42\n",
      "2021-05-06 01:51:06 [INFO]\t[TRAIN] Epoch=8/40, Step=2732/4124, loss=0.781328, time_each_step=0.31s, eta=11:20:42\n",
      "2021-05-06 01:52:07 [INFO]\t[TRAIN] Epoch=8/40, Step=2932/4124, loss=1.211856, time_each_step=0.31s, eta=11:19:46\n",
      "2021-05-06 01:53:08 [INFO]\t[TRAIN] Epoch=8/40, Step=3132/4124, loss=0.966163, time_each_step=0.3s, eta=11:18:37\n",
      "2021-05-06 01:54:09 [INFO]\t[TRAIN] Epoch=8/40, Step=3332/4124, loss=0.605406, time_each_step=0.3s, eta=11:17:37\n",
      "2021-05-06 01:55:10 [INFO]\t[TRAIN] Epoch=8/40, Step=3532/4124, loss=0.827115, time_each_step=0.3s, eta=11:16:36\n",
      "2021-05-06 01:56:11 [INFO]\t[TRAIN] Epoch=8/40, Step=3732/4124, loss=0.787141, time_each_step=0.3s, eta=11:15:36\n",
      "2021-05-06 01:57:11 [INFO]\t[TRAIN] Epoch=8/40, Step=3932/4124, loss=0.747899, time_each_step=0.31s, eta=11:14:35\n",
      "2021-05-06 01:58:09 [INFO]\t[TRAIN] Epoch 8 finished, loss=0.845628 .\n",
      "2021-05-06 01:58:09 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 01:58:16 [INFO]\t[EVAL] Finished, Epoch=8, miou=0.409502, category_iou=[0.42139299 0.64244479 0.35614102 0.21802754], oacc=0.606129, category_acc=[0.51060153 0.7986564  0.51211903 0.61262841], kappa=0.453707, category_F1-score=[0.5929296  0.78230306 0.52522712 0.358001  ] .\n",
      "2021-05-06 01:58:20 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-05-06 01:58:24 [INFO]\tModel saved in output/deeplab/epoch_8.\n",
      "2021-05-06 01:58:24 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_8, miou=0.40950158613611787\n",
      "2021-05-06 01:58:29 [INFO]\t[TRAIN] Epoch=9/40, Step=8/4124, loss=1.051283, time_each_step=0.46s, eta=11:25:25\n",
      "2021-05-06 01:59:31 [INFO]\t[TRAIN] Epoch=9/40, Step=208/4124, loss=0.80241, time_each_step=0.3s, eta=11:13:39\n",
      "2021-05-06 02:00:32 [INFO]\t[TRAIN] Epoch=9/40, Step=408/4124, loss=0.981122, time_each_step=0.31s, eta=11:13:10\n",
      "2021-05-06 02:01:32 [INFO]\t[TRAIN] Epoch=9/40, Step=608/4124, loss=0.485663, time_each_step=0.31s, eta=11:12:7\n",
      "2021-05-06 02:02:33 [INFO]\t[TRAIN] Epoch=9/40, Step=808/4124, loss=0.752568, time_each_step=0.3s, eta=11:10:59\n",
      "2021-05-06 02:03:34 [INFO]\t[TRAIN] Epoch=9/40, Step=1008/4124, loss=0.928846, time_each_step=0.31s, eta=11:10:4\n",
      "2021-05-06 02:04:35 [INFO]\t[TRAIN] Epoch=9/40, Step=1208/4124, loss=0.67324, time_each_step=0.31s, eta=11:9:3\n",
      "2021-05-06 02:05:35 [INFO]\t[TRAIN] Epoch=9/40, Step=1408/4124, loss=0.924952, time_each_step=0.3s, eta=11:7:56\n",
      "2021-05-06 02:06:37 [INFO]\t[TRAIN] Epoch=9/40, Step=1608/4124, loss=0.824518, time_each_step=0.3s, eta=11:6:58\n",
      "2021-05-06 02:07:37 [INFO]\t[TRAIN] Epoch=9/40, Step=1808/4124, loss=0.694417, time_each_step=0.3s, eta=11:5:56\n",
      "2021-05-06 02:08:38 [INFO]\t[TRAIN] Epoch=9/40, Step=2008/4124, loss=1.071218, time_each_step=0.3s, eta=11:4:55\n",
      "2021-05-06 02:09:39 [INFO]\t[TRAIN] Epoch=9/40, Step=2208/4124, loss=0.81944, time_each_step=0.31s, eta=11:4:4\n",
      "2021-05-06 02:10:40 [INFO]\t[TRAIN] Epoch=9/40, Step=2408/4124, loss=0.640703, time_each_step=0.3s, eta=11:2:54\n",
      "2021-05-06 02:11:41 [INFO]\t[TRAIN] Epoch=9/40, Step=2608/4124, loss=0.848016, time_each_step=0.31s, eta=11:2:0\n",
      "2021-05-06 02:12:41 [INFO]\t[TRAIN] Epoch=9/40, Step=2808/4124, loss=0.910047, time_each_step=0.3s, eta=11:0:51\n",
      "2021-05-06 02:13:42 [INFO]\t[TRAIN] Epoch=9/40, Step=3008/4124, loss=1.192148, time_each_step=0.3s, eta=10:59:51\n",
      "2021-05-06 02:14:43 [INFO]\t[TRAIN] Epoch=9/40, Step=3208/4124, loss=0.910968, time_each_step=0.3s, eta=10:58:50\n",
      "2021-05-06 02:15:44 [INFO]\t[TRAIN] Epoch=9/40, Step=3408/4124, loss=0.874346, time_each_step=0.3s, eta=10:57:51\n",
      "2021-05-06 02:16:45 [INFO]\t[TRAIN] Epoch=9/40, Step=3608/4124, loss=0.752758, time_each_step=0.3s, eta=10:56:49\n",
      "2021-05-06 02:17:46 [INFO]\t[TRAIN] Epoch=9/40, Step=3808/4124, loss=0.644611, time_each_step=0.3s, eta=10:55:48\n",
      "2021-05-06 02:18:47 [INFO]\t[TRAIN] Epoch=9/40, Step=4008/4124, loss=0.843618, time_each_step=0.3s, eta=10:54:48\n",
      "2021-05-06 02:19:22 [INFO]\t[TRAIN] Epoch 9 finished, loss=0.836205 .\n",
      "2021-05-06 02:19:52 [INFO]\t[TRAIN] Epoch=10/40, Step=84/4124, loss=0.819973, time_each_step=0.31s, eta=10:53:38\n",
      "2021-05-06 02:20:53 [INFO]\t[TRAIN] Epoch=10/40, Step=284/4124, loss=0.900821, time_each_step=0.31s, eta=10:52:45\n",
      "2021-05-06 02:21:54 [INFO]\t[TRAIN] Epoch=10/40, Step=484/4124, loss=1.187896, time_each_step=0.3s, eta=10:51:23\n",
      "2021-05-06 02:22:54 [INFO]\t[TRAIN] Epoch=10/40, Step=684/4124, loss=0.749185, time_each_step=0.31s, eta=10:50:23\n",
      "2021-05-06 02:23:55 [INFO]\t[TRAIN] Epoch=10/40, Step=884/4124, loss=0.539348, time_each_step=0.3s, eta=10:49:8\n",
      "2021-05-06 02:24:56 [INFO]\t[TRAIN] Epoch=10/40, Step=1084/4124, loss=1.513257, time_each_step=0.3s, eta=10:48:10\n",
      "2021-05-06 02:25:57 [INFO]\t[TRAIN] Epoch=10/40, Step=1284/4124, loss=0.926289, time_each_step=0.31s, eta=10:47:39\n",
      "2021-05-06 02:26:58 [INFO]\t[TRAIN] Epoch=10/40, Step=1484/4124, loss=0.729473, time_each_step=0.3s, eta=10:46:8\n",
      "2021-05-06 02:27:59 [INFO]\t[TRAIN] Epoch=10/40, Step=1684/4124, loss=0.773512, time_each_step=0.3s, eta=10:45:13\n",
      "2021-05-06 02:29:00 [INFO]\t[TRAIN] Epoch=10/40, Step=1884/4124, loss=0.994845, time_each_step=0.3s, eta=10:44:14\n",
      "2021-05-06 02:30:00 [INFO]\t[TRAIN] Epoch=10/40, Step=2084/4124, loss=1.123376, time_each_step=0.3s, eta=10:43:12\n",
      "2021-05-06 02:31:01 [INFO]\t[TRAIN] Epoch=10/40, Step=2284/4124, loss=0.6003, time_each_step=0.3s, eta=10:42:11\n",
      "2021-05-06 02:32:02 [INFO]\t[TRAIN] Epoch=10/40, Step=2484/4124, loss=0.929008, time_each_step=0.3s, eta=10:41:7\n",
      "2021-05-06 02:33:03 [INFO]\t[TRAIN] Epoch=10/40, Step=2684/4124, loss=0.674773, time_each_step=0.3s, eta=10:40:9\n",
      "2021-05-06 02:34:04 [INFO]\t[TRAIN] Epoch=10/40, Step=2884/4124, loss=0.728118, time_each_step=0.3s, eta=10:39:7\n",
      "2021-05-06 02:35:05 [INFO]\t[TRAIN] Epoch=10/40, Step=3084/4124, loss=0.841717, time_each_step=0.31s, eta=10:38:14\n",
      "2021-05-06 02:36:06 [INFO]\t[TRAIN] Epoch=10/40, Step=3284/4124, loss=1.415814, time_each_step=0.31s, eta=10:37:12\n",
      "2021-05-06 02:37:07 [INFO]\t[TRAIN] Epoch=10/40, Step=3484/4124, loss=0.66605, time_each_step=0.3s, eta=10:36:7\n",
      "2021-05-06 02:38:08 [INFO]\t[TRAIN] Epoch=10/40, Step=3684/4124, loss=0.968248, time_each_step=0.3s, eta=10:35:6\n",
      "2021-05-06 02:39:08 [INFO]\t[TRAIN] Epoch=10/40, Step=3884/4124, loss=0.622077, time_each_step=0.3s, eta=10:34:5\n",
      "2021-05-06 02:40:09 [INFO]\t[TRAIN] Epoch=10/40, Step=4084/4124, loss=1.130043, time_each_step=0.3s, eta=10:33:4\n",
      "2021-05-06 02:40:21 [INFO]\t[TRAIN] Epoch 10 finished, loss=0.81793 .\n",
      "2021-05-06 02:40:21 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 02:40:29 [INFO]\t[EVAL] Finished, Epoch=10, miou=0.377559, category_iou=[0.39749374 0.59242555 0.31254815 0.20776977], oacc=0.582805, category_acc=[0.59155353 0.6450102  0.48604878 0.46881968], kappa=0.422627, category_F1-score=[0.56886658 0.74405431 0.47624638 0.34405526] .\n",
      "2021-05-06 02:40:33 [INFO]\tModel saved in output/deeplab/epoch_10.\n",
      "2021-05-06 02:40:33 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_8, miou=0.40950158613611787\n",
      "2021-05-06 02:41:27 [INFO]\t[TRAIN] Epoch=11/40, Step=160/4124, loss=0.63805, time_each_step=0.3s, eta=10:31:45\n",
      "2021-05-06 02:42:28 [INFO]\t[TRAIN] Epoch=11/40, Step=360/4124, loss=1.117543, time_each_step=0.31s, eta=10:30:56\n",
      "2021-05-06 02:43:29 [INFO]\t[TRAIN] Epoch=11/40, Step=560/4124, loss=0.835414, time_each_step=0.3s, eta=10:29:36\n",
      "2021-05-06 02:44:30 [INFO]\t[TRAIN] Epoch=11/40, Step=760/4124, loss=0.94205, time_each_step=0.31s, eta=10:28:48\n",
      "2021-05-06 02:45:30 [INFO]\t[TRAIN] Epoch=11/40, Step=960/4124, loss=0.606136, time_each_step=0.3s, eta=10:27:27\n",
      "2021-05-06 02:46:31 [INFO]\t[TRAIN] Epoch=11/40, Step=1160/4124, loss=1.000604, time_each_step=0.3s, eta=10:26:37\n",
      "2021-05-06 02:47:32 [INFO]\t[TRAIN] Epoch=11/40, Step=1360/4124, loss=0.816771, time_each_step=0.31s, eta=10:25:43\n",
      "2021-05-06 02:48:33 [INFO]\t[TRAIN] Epoch=11/40, Step=1560/4124, loss=0.927231, time_each_step=0.3s, eta=10:24:39\n",
      "2021-05-06 02:49:34 [INFO]\t[TRAIN] Epoch=11/40, Step=1760/4124, loss=0.665379, time_each_step=0.3s, eta=10:23:38\n",
      "2021-05-06 02:50:35 [INFO]\t[TRAIN] Epoch=11/40, Step=1960/4124, loss=0.316048, time_each_step=0.3s, eta=10:22:33\n",
      "2021-05-06 02:51:35 [INFO]\t[TRAIN] Epoch=11/40, Step=2160/4124, loss=0.565625, time_each_step=0.3s, eta=10:21:32\n",
      "2021-05-06 02:52:36 [INFO]\t[TRAIN] Epoch=11/40, Step=2360/4124, loss=0.704336, time_each_step=0.3s, eta=10:20:34\n",
      "2021-05-06 02:53:37 [INFO]\t[TRAIN] Epoch=11/40, Step=2560/4124, loss=0.863555, time_each_step=0.3s, eta=10:19:31\n",
      "2021-05-06 02:54:38 [INFO]\t[TRAIN] Epoch=11/40, Step=2760/4124, loss=0.575848, time_each_step=0.3s, eta=10:18:29\n",
      "2021-05-06 02:55:39 [INFO]\t[TRAIN] Epoch=11/40, Step=2960/4124, loss=0.532566, time_each_step=0.3s, eta=10:17:28\n",
      "2021-05-06 02:56:40 [INFO]\t[TRAIN] Epoch=11/40, Step=3160/4124, loss=1.049699, time_each_step=0.3s, eta=10:16:29\n",
      "2021-05-06 02:57:41 [INFO]\t[TRAIN] Epoch=11/40, Step=3360/4124, loss=0.741055, time_each_step=0.31s, eta=10:15:37\n",
      "2021-05-06 02:58:42 [INFO]\t[TRAIN] Epoch=11/40, Step=3560/4124, loss=0.71385, time_each_step=0.3s, eta=10:14:28\n",
      "2021-05-06 02:59:42 [INFO]\t[TRAIN] Epoch=11/40, Step=3760/4124, loss=0.492197, time_each_step=0.3s, eta=10:13:28\n",
      "2021-05-06 03:00:43 [INFO]\t[TRAIN] Epoch=11/40, Step=3960/4124, loss=1.074243, time_each_step=0.3s, eta=10:12:27\n",
      "2021-05-06 03:01:33 [INFO]\t[TRAIN] Epoch 11 finished, loss=0.807957 .\n",
      "2021-05-06 03:01:48 [INFO]\t[TRAIN] Epoch=12/40, Step=36/4124, loss=0.725574, time_each_step=0.32s, eta=10:12:30\n",
      "2021-05-06 03:02:49 [INFO]\t[TRAIN] Epoch=12/40, Step=236/4124, loss=0.642859, time_each_step=0.3s, eta=10:10:27\n",
      "2021-05-06 03:03:50 [INFO]\t[TRAIN] Epoch=12/40, Step=436/4124, loss=0.651013, time_each_step=0.3s, eta=10:9:29\n",
      "2021-05-06 03:04:51 [INFO]\t[TRAIN] Epoch=12/40, Step=636/4124, loss=0.587004, time_each_step=0.31s, eta=10:8:41\n",
      "2021-05-06 03:05:52 [INFO]\t[TRAIN] Epoch=12/40, Step=836/4124, loss=0.758527, time_each_step=0.3s, eta=10:7:26\n",
      "2021-05-06 03:06:52 [INFO]\t[TRAIN] Epoch=12/40, Step=1036/4124, loss=1.057733, time_each_step=0.3s, eta=10:6:21\n",
      "2021-05-06 03:07:53 [INFO]\t[TRAIN] Epoch=12/40, Step=1236/4124, loss=0.722995, time_each_step=0.3s, eta=10:5:23\n",
      "2021-05-06 03:08:54 [INFO]\t[TRAIN] Epoch=12/40, Step=1436/4124, loss=0.85714, time_each_step=0.3s, eta=10:4:28\n",
      "2021-05-06 03:09:55 [INFO]\t[TRAIN] Epoch=12/40, Step=1636/4124, loss=0.755733, time_each_step=0.3s, eta=10:3:25\n",
      "2021-05-06 03:10:56 [INFO]\t[TRAIN] Epoch=12/40, Step=1836/4124, loss=0.820304, time_each_step=0.3s, eta=10:2:24\n",
      "2021-05-06 03:11:57 [INFO]\t[TRAIN] Epoch=12/40, Step=2036/4124, loss=0.739159, time_each_step=0.31s, eta=10:1:34\n",
      "2021-05-06 03:12:57 [INFO]\t[TRAIN] Epoch=12/40, Step=2236/4124, loss=0.727732, time_each_step=0.31s, eta=10:0:26\n",
      "2021-05-06 03:13:58 [INFO]\t[TRAIN] Epoch=12/40, Step=2436/4124, loss=0.937465, time_each_step=0.3s, eta=9:59:19\n",
      "2021-05-06 03:14:59 [INFO]\t[TRAIN] Epoch=12/40, Step=2636/4124, loss=0.938009, time_each_step=0.3s, eta=9:58:23\n",
      "2021-05-06 03:16:00 [INFO]\t[TRAIN] Epoch=12/40, Step=2836/4124, loss=0.890058, time_each_step=0.3s, eta=9:57:21\n",
      "2021-05-06 03:17:00 [INFO]\t[TRAIN] Epoch=12/40, Step=3036/4124, loss=0.492693, time_each_step=0.31s, eta=9:56:23\n",
      "2021-05-06 03:18:01 [INFO]\t[TRAIN] Epoch=12/40, Step=3236/4124, loss=0.478323, time_each_step=0.3s, eta=9:55:20\n",
      "2021-05-06 03:19:02 [INFO]\t[TRAIN] Epoch=12/40, Step=3436/4124, loss=0.404844, time_each_step=0.31s, eta=9:54:19\n",
      "2021-05-06 03:20:03 [INFO]\t[TRAIN] Epoch=12/40, Step=3636/4124, loss=1.163466, time_each_step=0.3s, eta=9:53:17\n",
      "2021-05-06 03:21:03 [INFO]\t[TRAIN] Epoch=12/40, Step=3836/4124, loss=0.791632, time_each_step=0.31s, eta=9:52:18\n",
      "2021-05-06 03:22:04 [INFO]\t[TRAIN] Epoch=12/40, Step=4036/4124, loss=0.546115, time_each_step=0.3s, eta=9:51:16\n",
      "2021-05-06 03:22:31 [INFO]\t[TRAIN] Epoch 12 finished, loss=0.792086 .\n",
      "2021-05-06 03:22:31 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 03:22:38 [INFO]\t[EVAL] Finished, Epoch=12, miou=0.431441, category_iou=[0.47395298 0.61120052 0.38003175 0.26057683], oacc=0.624147, category_acc=[0.54016531 0.83194007 0.59824416 0.52962585], kappa=0.478921, category_F1-score=[0.64310461 0.75868958 0.55075798 0.41342475] .\n",
      "2021-05-06 03:22:42 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-05-06 03:22:46 [INFO]\tModel saved in output/deeplab/epoch_12.\n",
      "2021-05-06 03:22:46 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_12, miou=0.4314405198951758\n",
      "2021-05-06 03:23:29 [INFO]\t[TRAIN] Epoch=13/40, Step=112/4124, loss=0.670886, time_each_step=0.3s, eta=9:49:52\n",
      "2021-05-06 03:24:30 [INFO]\t[TRAIN] Epoch=13/40, Step=312/4124, loss=0.453059, time_each_step=0.3s, eta=9:48:59\n",
      "2021-05-06 03:25:31 [INFO]\t[TRAIN] Epoch=13/40, Step=512/4124, loss=1.294505, time_each_step=0.3s, eta=9:47:48\n",
      "2021-05-06 03:26:32 [INFO]\t[TRAIN] Epoch=13/40, Step=712/4124, loss=0.612908, time_each_step=0.3s, eta=9:46:58\n",
      "2021-05-06 03:27:33 [INFO]\t[TRAIN] Epoch=13/40, Step=912/4124, loss=0.415116, time_each_step=0.3s, eta=9:45:49\n",
      "2021-05-06 03:28:33 [INFO]\t[TRAIN] Epoch=13/40, Step=1112/4124, loss=0.656899, time_each_step=0.3s, eta=9:44:50\n",
      "2021-05-06 03:29:34 [INFO]\t[TRAIN] Epoch=13/40, Step=1312/4124, loss=0.767376, time_each_step=0.3s, eta=9:43:50\n",
      "2021-05-06 03:30:35 [INFO]\t[TRAIN] Epoch=13/40, Step=1512/4124, loss=0.731351, time_each_step=0.31s, eta=9:42:56\n",
      "2021-05-06 03:31:36 [INFO]\t[TRAIN] Epoch=13/40, Step=1712/4124, loss=1.225199, time_each_step=0.3s, eta=9:41:50\n",
      "2021-05-06 03:32:37 [INFO]\t[TRAIN] Epoch=13/40, Step=1912/4124, loss=0.665945, time_each_step=0.3s, eta=9:40:50\n",
      "2021-05-06 03:33:38 [INFO]\t[TRAIN] Epoch=13/40, Step=2112/4124, loss=0.602947, time_each_step=0.3s, eta=9:39:49\n",
      "2021-05-06 03:34:39 [INFO]\t[TRAIN] Epoch=13/40, Step=2312/4124, loss=0.843652, time_each_step=0.3s, eta=9:38:50\n",
      "2021-05-06 03:35:40 [INFO]\t[TRAIN] Epoch=13/40, Step=2512/4124, loss=0.978058, time_each_step=0.31s, eta=9:37:53\n",
      "2021-05-06 03:36:41 [INFO]\t[TRAIN] Epoch=13/40, Step=2712/4124, loss=0.416265, time_each_step=0.3s, eta=9:36:47\n",
      "2021-05-06 03:37:42 [INFO]\t[TRAIN] Epoch=13/40, Step=2912/4124, loss=0.857052, time_each_step=0.31s, eta=9:35:48\n",
      "2021-05-06 03:38:42 [INFO]\t[TRAIN] Epoch=13/40, Step=3112/4124, loss=0.636054, time_each_step=0.3s, eta=9:34:46\n",
      "2021-05-06 03:39:43 [INFO]\t[TRAIN] Epoch=13/40, Step=3312/4124, loss=0.856886, time_each_step=0.3s, eta=9:33:45\n",
      "2021-05-06 03:40:44 [INFO]\t[TRAIN] Epoch=13/40, Step=3512/4124, loss=1.217077, time_each_step=0.3s, eta=9:32:43\n",
      "2021-05-06 03:41:45 [INFO]\t[TRAIN] Epoch=13/40, Step=3712/4124, loss=0.476768, time_each_step=0.3s, eta=9:31:43\n",
      "2021-05-06 03:42:46 [INFO]\t[TRAIN] Epoch=13/40, Step=3912/4124, loss=0.590656, time_each_step=0.31s, eta=9:30:44\n",
      "2021-05-06 03:43:47 [INFO]\t[TRAIN] Epoch=13/40, Step=4112/4124, loss=0.746495, time_each_step=0.3s, eta=9:29:42\n",
      "2021-05-06 03:43:51 [INFO]\t[TRAIN] Epoch 13 finished, loss=0.782842 .\n",
      "2021-05-06 03:44:53 [INFO]\t[TRAIN] Epoch=14/40, Step=188/4124, loss=1.003925, time_each_step=0.31s, eta=9:31:50\n",
      "2021-05-06 03:45:54 [INFO]\t[TRAIN] Epoch=14/40, Step=388/4124, loss=0.554377, time_each_step=0.31s, eta=9:30:37\n",
      "2021-05-06 03:46:54 [INFO]\t[TRAIN] Epoch=14/40, Step=588/4124, loss=0.495016, time_each_step=0.3s, eta=9:29:30\n",
      "2021-05-06 03:47:55 [INFO]\t[TRAIN] Epoch=14/40, Step=788/4124, loss=0.802524, time_each_step=0.31s, eta=9:28:39\n",
      "2021-05-06 03:48:56 [INFO]\t[TRAIN] Epoch=14/40, Step=988/4124, loss=0.737993, time_each_step=0.31s, eta=9:27:40\n",
      "2021-05-06 03:49:57 [INFO]\t[TRAIN] Epoch=14/40, Step=1188/4124, loss=1.408894, time_each_step=0.3s, eta=9:26:29\n",
      "2021-05-06 03:50:58 [INFO]\t[TRAIN] Epoch=14/40, Step=1388/4124, loss=0.991375, time_each_step=0.3s, eta=9:25:30\n",
      "2021-05-06 03:51:59 [INFO]\t[TRAIN] Epoch=14/40, Step=1588/4124, loss=0.573331, time_each_step=0.3s, eta=9:24:28\n",
      "2021-05-06 03:53:00 [INFO]\t[TRAIN] Epoch=14/40, Step=1788/4124, loss=0.614979, time_each_step=0.31s, eta=9:23:31\n",
      "2021-05-06 03:54:01 [INFO]\t[TRAIN] Epoch=14/40, Step=1988/4124, loss=0.629558, time_each_step=0.3s, eta=9:22:26\n",
      "2021-05-06 03:55:02 [INFO]\t[TRAIN] Epoch=14/40, Step=2188/4124, loss=0.57978, time_each_step=0.3s, eta=9:21:22\n",
      "2021-05-06 03:56:03 [INFO]\t[TRAIN] Epoch=14/40, Step=2388/4124, loss=1.04829, time_each_step=0.3s, eta=9:20:24\n",
      "2021-05-06 03:57:03 [INFO]\t[TRAIN] Epoch=14/40, Step=2588/4124, loss=1.149591, time_each_step=0.3s, eta=9:19:18\n",
      "2021-05-06 03:58:04 [INFO]\t[TRAIN] Epoch=14/40, Step=2788/4124, loss=0.813872, time_each_step=0.3s, eta=9:18:22\n",
      "2021-05-06 03:59:05 [INFO]\t[TRAIN] Epoch=14/40, Step=2988/4124, loss=0.997046, time_each_step=0.3s, eta=9:17:23\n",
      "2021-05-06 04:00:06 [INFO]\t[TRAIN] Epoch=14/40, Step=3188/4124, loss=0.809809, time_each_step=0.3s, eta=9:16:21\n",
      "2021-05-06 04:01:06 [INFO]\t[TRAIN] Epoch=14/40, Step=3388/4124, loss=0.999853, time_each_step=0.3s, eta=9:15:20\n",
      "2021-05-06 04:02:07 [INFO]\t[TRAIN] Epoch=14/40, Step=3588/4124, loss=0.863872, time_each_step=0.3s, eta=9:14:19\n",
      "2021-05-06 04:03:08 [INFO]\t[TRAIN] Epoch=14/40, Step=3788/4124, loss=0.567114, time_each_step=0.31s, eta=9:13:20\n",
      "2021-05-06 04:04:09 [INFO]\t[TRAIN] Epoch=14/40, Step=3988/4124, loss=0.611341, time_each_step=0.31s, eta=9:12:18\n",
      "2021-05-06 04:04:50 [INFO]\t[TRAIN] Epoch 14 finished, loss=0.770875 .\n",
      "2021-05-06 04:04:50 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 04:04:57 [INFO]\t[EVAL] Finished, Epoch=14, miou=0.373757, category_iou=[0.36504263 0.60254781 0.31840139 0.20903554], oacc=0.567086, category_acc=[0.58295604 0.69863926 0.41434302 0.44398932], kappa=0.410669, category_F1-score=[0.53484429 0.75198731 0.48301131 0.3457889 ] .\n",
      "2021-05-06 04:05:00 [INFO]\tModel saved in output/deeplab/epoch_14.\n",
      "2021-05-06 04:05:00 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_12, miou=0.4314405198951758\n",
      "2021-05-06 04:05:23 [INFO]\t[TRAIN] Epoch=15/40, Step=64/4124, loss=0.72249, time_each_step=0.31s, eta=9:8:12\n",
      "2021-05-06 04:06:24 [INFO]\t[TRAIN] Epoch=15/40, Step=264/4124, loss=0.621707, time_each_step=0.31s, eta=9:6:41\n",
      "2021-05-06 04:07:25 [INFO]\t[TRAIN] Epoch=15/40, Step=464/4124, loss=0.625333, time_each_step=0.31s, eta=9:5:43\n",
      "2021-05-06 04:08:26 [INFO]\t[TRAIN] Epoch=15/40, Step=664/4124, loss=0.750062, time_each_step=0.3s, eta=9:4:25\n",
      "2021-05-06 04:09:27 [INFO]\t[TRAIN] Epoch=15/40, Step=864/4124, loss=0.769762, time_each_step=0.3s, eta=9:3:16\n",
      "2021-05-06 04:10:28 [INFO]\t[TRAIN] Epoch=15/40, Step=1064/4124, loss=0.63858, time_each_step=0.31s, eta=9:2:31\n",
      "2021-05-06 04:11:28 [INFO]\t[TRAIN] Epoch=15/40, Step=1264/4124, loss=0.819505, time_each_step=0.31s, eta=9:1:28\n",
      "2021-05-06 04:12:29 [INFO]\t[TRAIN] Epoch=15/40, Step=1464/4124, loss=0.56984, time_each_step=0.3s, eta=9:0:23\n",
      "2021-05-06 04:13:30 [INFO]\t[TRAIN] Epoch=15/40, Step=1664/4124, loss=0.948918, time_each_step=0.3s, eta=8:59:22\n",
      "2021-05-06 04:14:31 [INFO]\t[TRAIN] Epoch=15/40, Step=1864/4124, loss=0.533166, time_each_step=0.3s, eta=8:58:19\n",
      "2021-05-06 04:15:32 [INFO]\t[TRAIN] Epoch=15/40, Step=2064/4124, loss=0.390994, time_each_step=0.3s, eta=8:57:20\n",
      "2021-05-06 04:16:33 [INFO]\t[TRAIN] Epoch=15/40, Step=2264/4124, loss=0.845518, time_each_step=0.3s, eta=8:56:16\n",
      "2021-05-06 04:17:33 [INFO]\t[TRAIN] Epoch=15/40, Step=2464/4124, loss=0.670372, time_each_step=0.3s, eta=8:55:17\n",
      "2021-05-06 04:18:34 [INFO]\t[TRAIN] Epoch=15/40, Step=2664/4124, loss=0.987997, time_each_step=0.3s, eta=8:54:18\n",
      "2021-05-06 04:19:35 [INFO]\t[TRAIN] Epoch=15/40, Step=2864/4124, loss=0.998371, time_each_step=0.3s, eta=8:53:16\n",
      "2021-05-06 04:20:36 [INFO]\t[TRAIN] Epoch=15/40, Step=3064/4124, loss=0.86157, time_each_step=0.3s, eta=8:52:17\n",
      "2021-05-06 04:21:37 [INFO]\t[TRAIN] Epoch=15/40, Step=3264/4124, loss=0.379294, time_each_step=0.3s, eta=8:51:14\n",
      "2021-05-06 04:22:38 [INFO]\t[TRAIN] Epoch=15/40, Step=3464/4124, loss=1.879558, time_each_step=0.3s, eta=8:50:15\n",
      "2021-05-06 04:23:39 [INFO]\t[TRAIN] Epoch=15/40, Step=3664/4124, loss=0.618276, time_each_step=0.3s, eta=8:49:14\n",
      "2021-05-06 04:24:40 [INFO]\t[TRAIN] Epoch=15/40, Step=3864/4124, loss=0.577527, time_each_step=0.3s, eta=8:48:13\n",
      "2021-05-06 04:25:40 [INFO]\t[TRAIN] Epoch=15/40, Step=4064/4124, loss=0.662468, time_each_step=0.3s, eta=8:47:12\n",
      "2021-05-06 04:25:58 [INFO]\t[TRAIN] Epoch 15 finished, loss=0.757605 .\n",
      "2021-05-06 04:26:46 [INFO]\t[TRAIN] Epoch=16/40, Step=140/4124, loss=0.63109, time_each_step=0.3s, eta=8:45:31\n",
      "2021-05-06 04:27:47 [INFO]\t[TRAIN] Epoch=16/40, Step=340/4124, loss=0.844052, time_each_step=0.3s, eta=8:44:35\n",
      "2021-05-06 04:28:48 [INFO]\t[TRAIN] Epoch=16/40, Step=540/4124, loss=0.52768, time_each_step=0.3s, eta=8:43:16\n",
      "2021-05-06 04:29:49 [INFO]\t[TRAIN] Epoch=16/40, Step=740/4124, loss=1.01136, time_each_step=0.31s, eta=8:42:42\n",
      "2021-05-06 04:30:50 [INFO]\t[TRAIN] Epoch=16/40, Step=940/4124, loss=1.013931, time_each_step=0.31s, eta=8:41:45\n",
      "2021-05-06 04:31:51 [INFO]\t[TRAIN] Epoch=16/40, Step=1140/4124, loss=0.499736, time_each_step=0.3s, eta=8:40:34\n",
      "2021-05-06 04:32:51 [INFO]\t[TRAIN] Epoch=16/40, Step=1340/4124, loss=0.754256, time_each_step=0.3s, eta=8:39:25\n",
      "2021-05-06 04:33:52 [INFO]\t[TRAIN] Epoch=16/40, Step=1540/4124, loss=0.666509, time_each_step=0.3s, eta=8:38:31\n",
      "2021-05-06 04:34:53 [INFO]\t[TRAIN] Epoch=16/40, Step=1740/4124, loss=0.655503, time_each_step=0.3s, eta=8:37:30\n",
      "2021-05-06 04:35:54 [INFO]\t[TRAIN] Epoch=16/40, Step=1940/4124, loss=0.90365, time_each_step=0.3s, eta=8:36:29\n",
      "2021-05-06 04:36:55 [INFO]\t[TRAIN] Epoch=16/40, Step=2140/4124, loss=0.719952, time_each_step=0.3s, eta=8:35:27\n",
      "2021-05-06 04:37:56 [INFO]\t[TRAIN] Epoch=16/40, Step=2340/4124, loss=0.619624, time_each_step=0.31s, eta=8:34:35\n",
      "2021-05-06 04:38:57 [INFO]\t[TRAIN] Epoch=16/40, Step=2540/4124, loss=0.422544, time_each_step=0.3s, eta=8:33:26\n",
      "2021-05-06 04:39:57 [INFO]\t[TRAIN] Epoch=16/40, Step=2740/4124, loss=0.865049, time_each_step=0.3s, eta=8:32:27\n",
      "2021-05-06 04:40:58 [INFO]\t[TRAIN] Epoch=16/40, Step=2940/4124, loss=1.227742, time_each_step=0.31s, eta=8:31:37\n",
      "2021-05-06 04:42:00 [INFO]\t[TRAIN] Epoch=16/40, Step=3140/4124, loss=0.582492, time_each_step=0.31s, eta=8:30:36\n",
      "2021-05-06 04:43:01 [INFO]\t[TRAIN] Epoch=16/40, Step=3340/4124, loss=0.580585, time_each_step=0.3s, eta=8:29:23\n",
      "2021-05-06 04:44:02 [INFO]\t[TRAIN] Epoch=16/40, Step=3540/4124, loss=1.024248, time_each_step=0.31s, eta=8:28:26\n",
      "2021-05-06 04:45:03 [INFO]\t[TRAIN] Epoch=16/40, Step=3740/4124, loss=0.710505, time_each_step=0.3s, eta=8:27:22\n",
      "2021-05-06 04:46:03 [INFO]\t[TRAIN] Epoch=16/40, Step=3940/4124, loss=1.013379, time_each_step=0.3s, eta=8:26:22\n",
      "2021-05-06 04:46:59 [INFO]\t[TRAIN] Epoch 16 finished, loss=0.747159 .\n",
      "2021-05-06 04:46:59 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 04:47:06 [INFO]\t[EVAL] Finished, Epoch=16, miou=0.444684, category_iou=[0.48210881 0.66177607 0.40957596 0.2252741 ], oacc=0.641117, category_acc=[0.5649483  0.80375745 0.60746181 0.52588583], kappa=0.501914, category_F1-score=[0.65057141 0.79646841 0.58113358 0.36771217] .\n",
      "2021-05-06 04:47:10 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-05-06 04:47:13 [INFO]\tModel saved in output/deeplab/epoch_16.\n",
      "2021-05-06 04:47:13 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_16, miou=0.4446837358967246\n",
      "2021-05-06 04:47:22 [INFO]\t[TRAIN] Epoch=17/40, Step=16/4124, loss=0.795193, time_each_step=0.47s, eta=8:38:40\n",
      "2021-05-06 04:48:23 [INFO]\t[TRAIN] Epoch=17/40, Step=216/4124, loss=0.609844, time_each_step=0.3s, eta=8:25:46\n",
      "2021-05-06 04:49:24 [INFO]\t[TRAIN] Epoch=17/40, Step=416/4124, loss=1.129557, time_each_step=0.3s, eta=8:24:54\n",
      "2021-05-06 04:50:24 [INFO]\t[TRAIN] Epoch=17/40, Step=616/4124, loss=0.771853, time_each_step=0.3s, eta=8:23:53\n",
      "2021-05-06 04:51:25 [INFO]\t[TRAIN] Epoch=17/40, Step=816/4124, loss=0.617332, time_each_step=0.31s, eta=8:22:59\n",
      "2021-05-06 04:52:26 [INFO]\t[TRAIN] Epoch=17/40, Step=1016/4124, loss=0.540554, time_each_step=0.3s, eta=8:21:51\n",
      "2021-05-06 04:53:27 [INFO]\t[TRAIN] Epoch=17/40, Step=1216/4124, loss=0.837477, time_each_step=0.31s, eta=8:21:7\n",
      "2021-05-06 04:54:27 [INFO]\t[TRAIN] Epoch=17/40, Step=1416/4124, loss=0.556021, time_each_step=0.31s, eta=8:19:57\n",
      "2021-05-06 04:55:28 [INFO]\t[TRAIN] Epoch=17/40, Step=1616/4124, loss=0.665901, time_each_step=0.3s, eta=8:18:53\n",
      "2021-05-06 04:56:30 [INFO]\t[TRAIN] Epoch=17/40, Step=1816/4124, loss=0.758229, time_each_step=0.3s, eta=8:17:47\n",
      "2021-05-06 04:57:30 [INFO]\t[TRAIN] Epoch=17/40, Step=2016/4124, loss=0.771053, time_each_step=0.3s, eta=8:16:48\n",
      "2021-05-06 04:58:31 [INFO]\t[TRAIN] Epoch=17/40, Step=2216/4124, loss=0.751503, time_each_step=0.31s, eta=8:15:53\n",
      "2021-05-06 04:59:32 [INFO]\t[TRAIN] Epoch=17/40, Step=2416/4124, loss=0.58568, time_each_step=0.3s, eta=8:14:46\n",
      "2021-05-06 05:00:33 [INFO]\t[TRAIN] Epoch=17/40, Step=2616/4124, loss=0.657724, time_each_step=0.31s, eta=8:13:54\n",
      "2021-05-06 05:01:33 [INFO]\t[TRAIN] Epoch=17/40, Step=2816/4124, loss=0.578196, time_each_step=0.3s, eta=8:12:41\n",
      "2021-05-06 05:02:34 [INFO]\t[TRAIN] Epoch=17/40, Step=3016/4124, loss=1.179626, time_each_step=0.3s, eta=8:11:46\n",
      "2021-05-06 05:03:35 [INFO]\t[TRAIN] Epoch=17/40, Step=3216/4124, loss=0.724754, time_each_step=0.3s, eta=8:10:45\n",
      "2021-05-06 05:04:36 [INFO]\t[TRAIN] Epoch=17/40, Step=3416/4124, loss=1.06701, time_each_step=0.3s, eta=8:9:44\n",
      "2021-05-06 05:05:37 [INFO]\t[TRAIN] Epoch=17/40, Step=3616/4124, loss=0.998787, time_each_step=0.3s, eta=8:8:43\n",
      "2021-05-06 05:06:37 [INFO]\t[TRAIN] Epoch=17/40, Step=3816/4124, loss=0.816273, time_each_step=0.3s, eta=8:7:43\n",
      "2021-05-06 05:07:38 [INFO]\t[TRAIN] Epoch=17/40, Step=4016/4124, loss=0.722151, time_each_step=0.3s, eta=8:6:42\n",
      "2021-05-06 05:08:11 [INFO]\t[TRAIN] Epoch 17 finished, loss=0.737996 .\n",
      "2021-05-06 05:08:43 [INFO]\t[TRAIN] Epoch=18/40, Step=92/4124, loss=1.357637, time_each_step=0.31s, eta=8:4:24\n",
      "2021-05-06 05:09:44 [INFO]\t[TRAIN] Epoch=18/40, Step=292/4124, loss=1.092013, time_each_step=0.3s, eta=8:3:17\n",
      "2021-05-06 05:10:45 [INFO]\t[TRAIN] Epoch=18/40, Step=492/4124, loss=0.977077, time_each_step=0.31s, eta=8:2:20\n",
      "2021-05-06 05:11:45 [INFO]\t[TRAIN] Epoch=18/40, Step=692/4124, loss=0.459831, time_each_step=0.31s, eta=8:1:20\n",
      "2021-05-06 05:12:46 [INFO]\t[TRAIN] Epoch=18/40, Step=892/4124, loss=0.629814, time_each_step=0.31s, eta=8:0:25\n",
      "2021-05-06 05:13:47 [INFO]\t[TRAIN] Epoch=18/40, Step=1092/4124, loss=0.899921, time_each_step=0.31s, eta=7:59:22\n",
      "2021-05-06 05:14:48 [INFO]\t[TRAIN] Epoch=18/40, Step=1292/4124, loss=0.752397, time_each_step=0.3s, eta=7:58:7\n",
      "2021-05-06 05:15:49 [INFO]\t[TRAIN] Epoch=18/40, Step=1492/4124, loss=0.413215, time_each_step=0.3s, eta=7:57:13\n",
      "2021-05-06 05:16:50 [INFO]\t[TRAIN] Epoch=18/40, Step=1692/4124, loss=0.60936, time_each_step=0.3s, eta=7:56:8\n",
      "2021-05-06 05:17:51 [INFO]\t[TRAIN] Epoch=18/40, Step=1892/4124, loss=0.5238, time_each_step=0.3s, eta=7:55:11\n",
      "2021-05-06 05:18:52 [INFO]\t[TRAIN] Epoch=18/40, Step=2092/4124, loss=0.558123, time_each_step=0.3s, eta=7:54:10\n",
      "2021-05-06 05:19:52 [INFO]\t[TRAIN] Epoch=18/40, Step=2292/4124, loss=0.770237, time_each_step=0.31s, eta=7:53:11\n",
      "2021-05-06 05:20:53 [INFO]\t[TRAIN] Epoch=18/40, Step=2492/4124, loss=0.759499, time_each_step=0.3s, eta=7:52:8\n",
      "2021-05-06 05:21:54 [INFO]\t[TRAIN] Epoch=18/40, Step=2692/4124, loss=0.618336, time_each_step=0.3s, eta=7:51:8\n",
      "2021-05-06 05:22:55 [INFO]\t[TRAIN] Epoch=18/40, Step=2892/4124, loss=1.015634, time_each_step=0.3s, eta=7:50:7\n",
      "2021-05-06 05:23:56 [INFO]\t[TRAIN] Epoch=18/40, Step=3092/4124, loss=0.876926, time_each_step=0.3s, eta=7:49:6\n",
      "2021-05-06 05:24:57 [INFO]\t[TRAIN] Epoch=18/40, Step=3292/4124, loss=1.342025, time_each_step=0.3s, eta=7:48:5\n",
      "2021-05-06 05:25:58 [INFO]\t[TRAIN] Epoch=18/40, Step=3492/4124, loss=0.793739, time_each_step=0.3s, eta=7:47:4\n",
      "2021-05-06 05:26:59 [INFO]\t[TRAIN] Epoch=18/40, Step=3692/4124, loss=0.936485, time_each_step=0.3s, eta=7:46:3\n",
      "2021-05-06 05:28:00 [INFO]\t[TRAIN] Epoch=18/40, Step=3892/4124, loss=0.85731, time_each_step=0.3s, eta=7:45:3\n",
      "2021-05-06 05:29:00 [INFO]\t[TRAIN] Epoch=18/40, Step=4092/4124, loss=0.832622, time_each_step=0.3s, eta=7:44:2\n",
      "2021-05-06 05:29:10 [INFO]\t[TRAIN] Epoch 18 finished, loss=0.727769 .\n",
      "2021-05-06 05:29:10 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 05:29:17 [INFO]\t[EVAL] Finished, Epoch=18, miou=0.383656, category_iou=[0.4017111  0.59754908 0.39182371 0.14353895], oacc=0.585712, category_acc=[0.59759561 0.6511099  0.55965261 0.34862887], kappa=0.427345, category_F1-score=[0.57317246 0.74808228 0.56303641 0.25104339] .\n",
      "2021-05-06 05:29:21 [INFO]\tModel saved in output/deeplab/epoch_18.\n",
      "2021-05-06 05:29:21 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_16, miou=0.4446837358967246\n",
      "2021-05-06 05:30:17 [INFO]\t[TRAIN] Epoch=19/40, Step=168/4124, loss=0.526515, time_each_step=0.31s, eta=7:42:53\n",
      "2021-05-06 05:31:17 [INFO]\t[TRAIN] Epoch=19/40, Step=368/4124, loss=0.853306, time_each_step=0.3s, eta=7:41:51\n",
      "2021-05-06 05:32:18 [INFO]\t[TRAIN] Epoch=19/40, Step=568/4124, loss=0.749889, time_each_step=0.3s, eta=7:40:47\n",
      "2021-05-06 05:33:19 [INFO]\t[TRAIN] Epoch=19/40, Step=768/4124, loss=0.423603, time_each_step=0.3s, eta=7:39:49\n",
      "2021-05-06 05:34:20 [INFO]\t[TRAIN] Epoch=19/40, Step=968/4124, loss=0.936107, time_each_step=0.3s, eta=7:38:41\n",
      "2021-05-06 05:35:21 [INFO]\t[TRAIN] Epoch=19/40, Step=1168/4124, loss=0.76641, time_each_step=0.3s, eta=7:37:41\n",
      "2021-05-06 05:36:21 [INFO]\t[TRAIN] Epoch=19/40, Step=1368/4124, loss=1.098705, time_each_step=0.3s, eta=7:36:39\n",
      "2021-05-06 05:37:22 [INFO]\t[TRAIN] Epoch=19/40, Step=1568/4124, loss=0.725709, time_each_step=0.3s, eta=7:35:34\n",
      "2021-05-06 05:38:23 [INFO]\t[TRAIN] Epoch=19/40, Step=1768/4124, loss=0.650625, time_each_step=0.31s, eta=7:34:47\n",
      "2021-05-06 05:39:24 [INFO]\t[TRAIN] Epoch=19/40, Step=1968/4124, loss=0.597192, time_each_step=0.3s, eta=7:33:41\n",
      "2021-05-06 05:40:25 [INFO]\t[TRAIN] Epoch=19/40, Step=2168/4124, loss=0.512131, time_each_step=0.3s, eta=7:32:39\n",
      "2021-05-06 05:41:26 [INFO]\t[TRAIN] Epoch=19/40, Step=2368/4124, loss=0.610116, time_each_step=0.3s, eta=7:31:40\n",
      "2021-05-06 05:42:26 [INFO]\t[TRAIN] Epoch=19/40, Step=2568/4124, loss=0.530204, time_each_step=0.3s, eta=7:30:35\n",
      "2021-05-06 05:43:27 [INFO]\t[TRAIN] Epoch=19/40, Step=2768/4124, loss=1.127419, time_each_step=0.3s, eta=7:29:38\n",
      "2021-05-06 05:44:28 [INFO]\t[TRAIN] Epoch=19/40, Step=2968/4124, loss=0.727002, time_each_step=0.3s, eta=7:28:36\n",
      "2021-05-06 05:45:29 [INFO]\t[TRAIN] Epoch=19/40, Step=3168/4124, loss=1.323302, time_each_step=0.3s, eta=7:27:36\n",
      "2021-05-06 05:46:29 [INFO]\t[TRAIN] Epoch=19/40, Step=3368/4124, loss=1.050039, time_each_step=0.3s, eta=7:26:34\n",
      "2021-05-06 05:47:30 [INFO]\t[TRAIN] Epoch=19/40, Step=3568/4124, loss=0.733347, time_each_step=0.3s, eta=7:25:35\n",
      "2021-05-06 05:48:31 [INFO]\t[TRAIN] Epoch=19/40, Step=3768/4124, loss=0.663347, time_each_step=0.3s, eta=7:24:35\n",
      "2021-05-06 05:49:32 [INFO]\t[TRAIN] Epoch=19/40, Step=3968/4124, loss=0.937465, time_each_step=0.3s, eta=7:23:33\n",
      "2021-05-06 05:50:19 [INFO]\t[TRAIN] Epoch 19 finished, loss=0.715319 .\n",
      "2021-05-06 05:50:37 [INFO]\t[TRAIN] Epoch=20/40, Step=44/4124, loss=0.956632, time_each_step=0.31s, eta=7:22:15\n",
      "2021-05-06 05:51:37 [INFO]\t[TRAIN] Epoch=20/40, Step=244/4124, loss=0.514083, time_each_step=0.3s, eta=7:20:54\n",
      "2021-05-06 05:52:38 [INFO]\t[TRAIN] Epoch=20/40, Step=444/4124, loss=0.673782, time_each_step=0.3s, eta=7:19:52\n",
      "2021-05-06 05:53:39 [INFO]\t[TRAIN] Epoch=20/40, Step=644/4124, loss=0.615439, time_each_step=0.31s, eta=7:19:2\n",
      "2021-05-06 05:54:40 [INFO]\t[TRAIN] Epoch=20/40, Step=844/4124, loss=0.558423, time_each_step=0.3s, eta=7:17:43\n",
      "2021-05-06 05:55:40 [INFO]\t[TRAIN] Epoch=20/40, Step=1044/4124, loss=0.603783, time_each_step=0.31s, eta=7:17:2\n",
      "2021-05-06 05:56:41 [INFO]\t[TRAIN] Epoch=20/40, Step=1244/4124, loss=0.832978, time_each_step=0.3s, eta=7:15:48\n",
      "2021-05-06 05:57:42 [INFO]\t[TRAIN] Epoch=20/40, Step=1444/4124, loss=0.791651, time_each_step=0.31s, eta=7:15:2\n",
      "2021-05-06 05:58:43 [INFO]\t[TRAIN] Epoch=20/40, Step=1644/4124, loss=0.79937, time_each_step=0.3s, eta=7:13:50\n",
      "2021-05-06 05:59:44 [INFO]\t[TRAIN] Epoch=20/40, Step=1844/4124, loss=0.826547, time_each_step=0.3s, eta=7:12:48\n",
      "2021-05-06 06:00:45 [INFO]\t[TRAIN] Epoch=20/40, Step=2044/4124, loss=0.794915, time_each_step=0.3s, eta=7:11:49\n",
      "2021-05-06 06:01:46 [INFO]\t[TRAIN] Epoch=20/40, Step=2244/4124, loss=1.020258, time_each_step=0.3s, eta=7:10:48\n",
      "2021-05-06 06:02:47 [INFO]\t[TRAIN] Epoch=20/40, Step=2444/4124, loss=0.91095, time_each_step=0.3s, eta=7:9:43\n",
      "2021-05-06 06:03:48 [INFO]\t[TRAIN] Epoch=20/40, Step=2644/4124, loss=0.617131, time_each_step=0.31s, eta=7:8:53\n",
      "2021-05-06 06:04:49 [INFO]\t[TRAIN] Epoch=20/40, Step=2844/4124, loss=0.768477, time_each_step=0.3s, eta=7:7:44\n",
      "2021-05-06 06:05:50 [INFO]\t[TRAIN] Epoch=20/40, Step=3044/4124, loss=0.824004, time_each_step=0.31s, eta=7:6:47\n",
      "2021-05-06 06:06:50 [INFO]\t[TRAIN] Epoch=20/40, Step=3244/4124, loss=0.426583, time_each_step=0.3s, eta=7:5:43\n",
      "2021-05-06 06:07:51 [INFO]\t[TRAIN] Epoch=20/40, Step=3444/4124, loss=1.018719, time_each_step=0.31s, eta=7:4:49\n",
      "2021-05-06 06:08:52 [INFO]\t[TRAIN] Epoch=20/40, Step=3644/4124, loss=0.497235, time_each_step=0.3s, eta=7:3:42\n",
      "2021-05-06 06:09:53 [INFO]\t[TRAIN] Epoch=20/40, Step=3844/4124, loss=1.062506, time_each_step=0.3s, eta=7:2:41\n",
      "2021-05-06 06:10:54 [INFO]\t[TRAIN] Epoch=20/40, Step=4044/4124, loss=1.111537, time_each_step=0.31s, eta=7:1:41\n",
      "2021-05-06 06:11:18 [INFO]\t[TRAIN] Epoch 20 finished, loss=0.70691 .\n",
      "2021-05-06 06:11:18 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 06:11:25 [INFO]\t[EVAL] Finished, Epoch=20, miou=0.479063, category_iou=[0.47189224 0.69032306 0.42868832 0.3253498 ], oacc=0.661178, category_acc=[0.65900114 0.79362392 0.59842388 0.49513823], kappa=0.537696, category_F1-score=[0.64120487 0.81679423 0.60011455 0.49096442] .\n",
      "2021-05-06 06:11:29 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-05-06 06:11:33 [INFO]\tModel saved in output/deeplab/epoch_20.\n",
      "2021-05-06 06:11:33 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_20, miou=0.47906335268593175\n",
      "2021-05-06 06:12:13 [INFO]\t[TRAIN] Epoch=21/40, Step=120/4124, loss=0.721056, time_each_step=0.3s, eta=7:1:18\n",
      "2021-05-06 06:13:14 [INFO]\t[TRAIN] Epoch=21/40, Step=320/4124, loss=0.734873, time_each_step=0.3s, eta=7:0:26\n",
      "2021-05-06 06:14:15 [INFO]\t[TRAIN] Epoch=21/40, Step=520/4124, loss=0.854484, time_each_step=0.3s, eta=6:59:3\n",
      "2021-05-06 06:15:16 [INFO]\t[TRAIN] Epoch=21/40, Step=720/4124, loss=0.641759, time_each_step=0.3s, eta=6:58:25\n",
      "2021-05-06 06:16:17 [INFO]\t[TRAIN] Epoch=21/40, Step=920/4124, loss=0.576598, time_each_step=0.31s, eta=6:57:29\n",
      "2021-05-06 06:17:18 [INFO]\t[TRAIN] Epoch=21/40, Step=1120/4124, loss=0.577534, time_each_step=0.3s, eta=6:56:26\n",
      "2021-05-06 06:18:18 [INFO]\t[TRAIN] Epoch=21/40, Step=1320/4124, loss=0.580336, time_each_step=0.3s, eta=6:55:24\n",
      "2021-05-06 06:19:19 [INFO]\t[TRAIN] Epoch=21/40, Step=1520/4124, loss=0.993406, time_each_step=0.3s, eta=6:54:21\n",
      "2021-05-06 06:20:20 [INFO]\t[TRAIN] Epoch=21/40, Step=1720/4124, loss=0.706704, time_each_step=0.31s, eta=6:53:32\n",
      "2021-05-06 06:21:21 [INFO]\t[TRAIN] Epoch=21/40, Step=1920/4124, loss=0.515516, time_each_step=0.3s, eta=6:52:20\n",
      "2021-05-06 06:22:22 [INFO]\t[TRAIN] Epoch=21/40, Step=2120/4124, loss=0.609895, time_each_step=0.31s, eta=6:51:28\n",
      "2021-05-06 06:23:23 [INFO]\t[TRAIN] Epoch=21/40, Step=2320/4124, loss=0.756456, time_each_step=0.3s, eta=6:50:15\n",
      "2021-05-06 06:24:24 [INFO]\t[TRAIN] Epoch=21/40, Step=2520/4124, loss=0.459898, time_each_step=0.3s, eta=6:49:19\n",
      "2021-05-06 06:25:25 [INFO]\t[TRAIN] Epoch=21/40, Step=2720/4124, loss=0.646503, time_each_step=0.3s, eta=6:48:17\n",
      "2021-05-06 06:26:25 [INFO]\t[TRAIN] Epoch=21/40, Step=2920/4124, loss=0.504691, time_each_step=0.3s, eta=6:47:18\n",
      "2021-05-06 06:27:27 [INFO]\t[TRAIN] Epoch=21/40, Step=3120/4124, loss=0.624466, time_each_step=0.3s, eta=6:46:14\n",
      "2021-05-06 06:28:27 [INFO]\t[TRAIN] Epoch=21/40, Step=3320/4124, loss=0.492498, time_each_step=0.3s, eta=6:45:16\n",
      "2021-05-06 06:29:28 [INFO]\t[TRAIN] Epoch=21/40, Step=3520/4124, loss=0.444232, time_each_step=0.3s, eta=6:44:15\n",
      "2021-05-06 06:30:29 [INFO]\t[TRAIN] Epoch=21/40, Step=3720/4124, loss=0.692634, time_each_step=0.31s, eta=6:43:15\n",
      "2021-05-06 06:31:30 [INFO]\t[TRAIN] Epoch=21/40, Step=3920/4124, loss=0.444643, time_each_step=0.3s, eta=6:42:13\n",
      "2021-05-06 06:32:30 [INFO]\t[TRAIN] Epoch=21/40, Step=4120/4124, loss=0.696005, time_each_step=0.3s, eta=6:41:12\n",
      "2021-05-06 06:32:32 [INFO]\t[TRAIN] Epoch 21 finished, loss=0.696146 .\n",
      "2021-05-06 06:33:36 [INFO]\t[TRAIN] Epoch=22/40, Step=196/4124, loss=0.385587, time_each_step=0.3s, eta=6:40:0\n",
      "2021-05-06 06:34:37 [INFO]\t[TRAIN] Epoch=22/40, Step=396/4124, loss=0.895887, time_each_step=0.31s, eta=6:39:26\n",
      "2021-05-06 06:35:38 [INFO]\t[TRAIN] Epoch=22/40, Step=596/4124, loss=0.468012, time_each_step=0.3s, eta=6:38:0\n",
      "2021-05-06 06:36:39 [INFO]\t[TRAIN] Epoch=22/40, Step=796/4124, loss=0.708731, time_each_step=0.3s, eta=6:36:57\n",
      "2021-05-06 06:37:40 [INFO]\t[TRAIN] Epoch=22/40, Step=996/4124, loss=0.789918, time_each_step=0.3s, eta=6:35:52\n",
      "2021-05-06 06:38:40 [INFO]\t[TRAIN] Epoch=22/40, Step=1196/4124, loss=0.694347, time_each_step=0.3s, eta=6:34:52\n",
      "2021-05-06 06:39:41 [INFO]\t[TRAIN] Epoch=22/40, Step=1396/4124, loss=1.338025, time_each_step=0.31s, eta=6:34:4\n",
      "2021-05-06 06:40:42 [INFO]\t[TRAIN] Epoch=22/40, Step=1596/4124, loss=0.950755, time_each_step=0.3s, eta=6:32:56\n",
      "2021-05-06 06:41:43 [INFO]\t[TRAIN] Epoch=22/40, Step=1796/4124, loss=0.96232, time_each_step=0.3s, eta=6:31:54\n",
      "2021-05-06 06:42:44 [INFO]\t[TRAIN] Epoch=22/40, Step=1996/4124, loss=0.615344, time_each_step=0.3s, eta=6:30:51\n",
      "2021-05-06 06:43:45 [INFO]\t[TRAIN] Epoch=22/40, Step=2196/4124, loss=0.555487, time_each_step=0.3s, eta=6:29:50\n",
      "2021-05-06 06:44:45 [INFO]\t[TRAIN] Epoch=22/40, Step=2396/4124, loss=0.738129, time_each_step=0.3s, eta=6:28:50\n",
      "2021-05-06 06:45:46 [INFO]\t[TRAIN] Epoch=22/40, Step=2596/4124, loss=0.503553, time_each_step=0.3s, eta=6:27:48\n",
      "2021-05-06 06:46:47 [INFO]\t[TRAIN] Epoch=22/40, Step=2796/4124, loss=0.862555, time_each_step=0.3s, eta=6:26:48\n",
      "2021-05-06 06:47:48 [INFO]\t[TRAIN] Epoch=22/40, Step=2996/4124, loss=0.719983, time_each_step=0.3s, eta=6:25:48\n",
      "2021-05-06 06:48:49 [INFO]\t[TRAIN] Epoch=22/40, Step=3196/4124, loss=0.642206, time_each_step=0.3s, eta=6:24:47\n",
      "2021-05-06 06:49:50 [INFO]\t[TRAIN] Epoch=22/40, Step=3396/4124, loss=0.787893, time_each_step=0.31s, eta=6:23:49\n",
      "2021-05-06 06:50:51 [INFO]\t[TRAIN] Epoch=22/40, Step=3596/4124, loss=0.810128, time_each_step=0.3s, eta=6:22:46\n",
      "2021-05-06 06:51:52 [INFO]\t[TRAIN] Epoch=22/40, Step=3796/4124, loss=0.803164, time_each_step=0.3s, eta=6:21:46\n",
      "2021-05-06 06:52:53 [INFO]\t[TRAIN] Epoch=22/40, Step=3996/4124, loss=0.405428, time_each_step=0.3s, eta=6:20:44\n",
      "2021-05-06 06:53:31 [INFO]\t[TRAIN] Epoch 22 finished, loss=0.685051 .\n",
      "2021-05-06 06:53:31 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 06:53:38 [INFO]\t[EVAL] Finished, Epoch=22, miou=0.436511, category_iou=[0.41490287 0.65423151 0.40994459 0.26696339], oacc=0.617699, category_acc=[0.60065398 0.82191576 0.49108808 0.47474753], kappa=0.48307, category_F1-score=[0.58647541 0.79097938 0.58150454 0.42142242] .\n",
      "2021-05-06 06:53:42 [INFO]\tModel saved in output/deeplab/epoch_22.\n",
      "2021-05-06 06:53:42 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_20, miou=0.47906335268593175\n",
      "2021-05-06 06:54:08 [INFO]\t[TRAIN] Epoch=23/40, Step=72/4124, loss=0.982545, time_each_step=0.31s, eta=6:19:14\n",
      "2021-05-06 06:55:08 [INFO]\t[TRAIN] Epoch=23/40, Step=272/4124, loss=0.40072, time_each_step=0.3s, eta=6:17:56\n",
      "2021-05-06 06:56:09 [INFO]\t[TRAIN] Epoch=23/40, Step=472/4124, loss=0.428381, time_each_step=0.31s, eta=6:17:6\n",
      "2021-05-06 06:57:10 [INFO]\t[TRAIN] Epoch=23/40, Step=672/4124, loss=0.566106, time_each_step=0.3s, eta=6:16:1\n",
      "2021-05-06 06:58:11 [INFO]\t[TRAIN] Epoch=23/40, Step=872/4124, loss=0.948026, time_each_step=0.3s, eta=6:14:52\n",
      "2021-05-06 06:59:11 [INFO]\t[TRAIN] Epoch=23/40, Step=1072/4124, loss=0.570478, time_each_step=0.3s, eta=6:13:55\n",
      "2021-05-06 07:00:12 [INFO]\t[TRAIN] Epoch=23/40, Step=1272/4124, loss=0.581434, time_each_step=0.3s, eta=6:12:53\n",
      "2021-05-06 07:01:13 [INFO]\t[TRAIN] Epoch=23/40, Step=1472/4124, loss=0.534122, time_each_step=0.3s, eta=6:11:49\n",
      "2021-05-06 07:02:13 [INFO]\t[TRAIN] Epoch=23/40, Step=1672/4124, loss=0.496957, time_each_step=0.3s, eta=6:10:57\n",
      "2021-05-06 07:03:14 [INFO]\t[TRAIN] Epoch=23/40, Step=1872/4124, loss=0.543917, time_each_step=0.31s, eta=6:9:59\n",
      "2021-05-06 07:04:15 [INFO]\t[TRAIN] Epoch=23/40, Step=2072/4124, loss=0.41541, time_each_step=0.3s, eta=6:8:56\n",
      "2021-05-06 07:05:16 [INFO]\t[TRAIN] Epoch=23/40, Step=2272/4124, loss=0.532937, time_each_step=0.31s, eta=6:8:6\n",
      "2021-05-06 07:06:17 [INFO]\t[TRAIN] Epoch=23/40, Step=2472/4124, loss=0.430194, time_each_step=0.3s, eta=6:6:53\n",
      "2021-05-06 07:07:17 [INFO]\t[TRAIN] Epoch=23/40, Step=2672/4124, loss=0.532165, time_each_step=0.3s, eta=6:5:53\n",
      "2021-05-06 07:08:18 [INFO]\t[TRAIN] Epoch=23/40, Step=2872/4124, loss=0.665952, time_each_step=0.3s, eta=6:4:53\n",
      "2021-05-06 07:09:19 [INFO]\t[TRAIN] Epoch=23/40, Step=3072/4124, loss=0.572416, time_each_step=0.3s, eta=6:3:50\n",
      "2021-05-06 07:10:20 [INFO]\t[TRAIN] Epoch=23/40, Step=3272/4124, loss=0.916477, time_each_step=0.3s, eta=6:2:49\n",
      "2021-05-06 07:11:21 [INFO]\t[TRAIN] Epoch=23/40, Step=3472/4124, loss=0.362392, time_each_step=0.31s, eta=6:1:52\n",
      "2021-05-06 07:12:22 [INFO]\t[TRAIN] Epoch=23/40, Step=3672/4124, loss=0.69832, time_each_step=0.3s, eta=6:0:48\n",
      "2021-05-06 07:13:23 [INFO]\t[TRAIN] Epoch=23/40, Step=3872/4124, loss=0.760816, time_each_step=0.3s, eta=5:59:47\n",
      "2021-05-06 07:14:23 [INFO]\t[TRAIN] Epoch=23/40, Step=4072/4124, loss=1.1287, time_each_step=0.3s, eta=5:58:47\n",
      "2021-05-06 07:14:39 [INFO]\t[TRAIN] Epoch 23 finished, loss=0.673775 .\n",
      "2021-05-06 07:15:28 [INFO]\t[TRAIN] Epoch=24/40, Step=148/4124, loss=1.127302, time_each_step=0.3s, eta=5:56:57\n",
      "2021-05-06 07:16:29 [INFO]\t[TRAIN] Epoch=24/40, Step=348/4124, loss=0.643123, time_each_step=0.31s, eta=5:56:9\n",
      "2021-05-06 07:17:29 [INFO]\t[TRAIN] Epoch=24/40, Step=548/4124, loss=0.685092, time_each_step=0.3s, eta=5:54:38\n",
      "2021-05-06 07:18:30 [INFO]\t[TRAIN] Epoch=24/40, Step=748/4124, loss=0.504179, time_each_step=0.31s, eta=5:53:55\n",
      "2021-05-06 07:19:31 [INFO]\t[TRAIN] Epoch=24/40, Step=948/4124, loss=0.433735, time_each_step=0.31s, eta=5:52:55\n",
      "2021-05-06 07:20:31 [INFO]\t[TRAIN] Epoch=24/40, Step=1148/4124, loss=0.572184, time_each_step=0.3s, eta=5:51:45\n",
      "2021-05-06 07:21:32 [INFO]\t[TRAIN] Epoch=24/40, Step=1348/4124, loss=0.428012, time_each_step=0.31s, eta=5:50:52\n",
      "2021-05-06 07:22:33 [INFO]\t[TRAIN] Epoch=24/40, Step=1548/4124, loss=0.432684, time_each_step=0.3s, eta=5:49:41\n",
      "2021-05-06 07:23:34 [INFO]\t[TRAIN] Epoch=24/40, Step=1748/4124, loss=0.811623, time_each_step=0.3s, eta=5:48:45\n",
      "2021-05-06 07:24:35 [INFO]\t[TRAIN] Epoch=24/40, Step=1948/4124, loss=0.796676, time_each_step=0.3s, eta=5:47:38\n",
      "2021-05-06 07:25:35 [INFO]\t[TRAIN] Epoch=24/40, Step=2148/4124, loss=0.50175, time_each_step=0.3s, eta=5:46:42\n",
      "2021-05-06 07:26:36 [INFO]\t[TRAIN] Epoch=24/40, Step=2348/4124, loss=0.510411, time_each_step=0.3s, eta=5:45:44\n",
      "2021-05-06 07:27:37 [INFO]\t[TRAIN] Epoch=24/40, Step=2548/4124, loss=0.580364, time_each_step=0.31s, eta=5:44:46\n",
      "2021-05-06 07:28:38 [INFO]\t[TRAIN] Epoch=24/40, Step=2748/4124, loss=0.66888, time_each_step=0.3s, eta=5:43:40\n",
      "2021-05-06 07:29:39 [INFO]\t[TRAIN] Epoch=24/40, Step=2948/4124, loss=0.475943, time_each_step=0.3s, eta=5:42:42\n",
      "2021-05-06 07:30:39 [INFO]\t[TRAIN] Epoch=24/40, Step=3148/4124, loss=0.580525, time_each_step=0.3s, eta=5:41:40\n",
      "2021-05-06 07:31:40 [INFO]\t[TRAIN] Epoch=24/40, Step=3348/4124, loss=0.568585, time_each_step=0.3s, eta=5:40:39\n",
      "2021-05-06 07:32:41 [INFO]\t[TRAIN] Epoch=24/40, Step=3548/4124, loss=0.457901, time_each_step=0.31s, eta=5:39:40\n",
      "2021-05-06 07:33:42 [INFO]\t[TRAIN] Epoch=24/40, Step=3748/4124, loss=0.942938, time_each_step=0.3s, eta=5:38:38\n",
      "2021-05-06 07:34:43 [INFO]\t[TRAIN] Epoch=24/40, Step=3948/4124, loss=0.538895, time_each_step=0.3s, eta=5:37:38\n",
      "2021-05-06 07:35:36 [INFO]\t[TRAIN] Epoch 24 finished, loss=0.665758 .\n",
      "2021-05-06 07:35:36 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 07:35:43 [INFO]\t[EVAL] Finished, Epoch=24, miou=0.481712, category_iou=[0.49132758 0.66228145 0.46761755 0.30562049], oacc=0.660736, category_acc=[0.65720874 0.81198239 0.59779668 0.48639415], kappa=0.53838, category_F1-score=[0.65891302 0.79683432 0.63724715 0.46816129] .\n",
      "2021-05-06 07:35:47 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-05-06 07:35:50 [INFO]\tModel saved in output/deeplab/epoch_24.\n",
      "2021-05-06 07:35:50 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_24, miou=0.48171176775851454\n",
      "2021-05-06 07:36:01 [INFO]\t[TRAIN] Epoch=25/40, Step=24/4124, loss=0.527752, time_each_step=0.32s, eta=5:38:14\n",
      "2021-05-06 07:37:02 [INFO]\t[TRAIN] Epoch=25/40, Step=224/4124, loss=0.602938, time_each_step=0.3s, eta=5:35:47\n",
      "2021-05-06 07:38:03 [INFO]\t[TRAIN] Epoch=25/40, Step=424/4124, loss=0.650464, time_each_step=0.31s, eta=5:35:11\n",
      "2021-05-06 07:39:04 [INFO]\t[TRAIN] Epoch=25/40, Step=624/4124, loss=0.327551, time_each_step=0.31s, eta=5:34:23\n",
      "2021-05-06 07:40:05 [INFO]\t[TRAIN] Epoch=25/40, Step=824/4124, loss=0.728813, time_each_step=0.31s, eta=5:33:0\n",
      "2021-05-06 07:41:05 [INFO]\t[TRAIN] Epoch=25/40, Step=1024/4124, loss=0.705157, time_each_step=0.31s, eta=5:31:56\n",
      "2021-05-06 07:42:06 [INFO]\t[TRAIN] Epoch=25/40, Step=1224/4124, loss=0.808632, time_each_step=0.3s, eta=5:30:48\n",
      "2021-05-06 07:43:07 [INFO]\t[TRAIN] Epoch=25/40, Step=1424/4124, loss=0.470062, time_each_step=0.3s, eta=5:29:54\n",
      "2021-05-06 07:44:08 [INFO]\t[TRAIN] Epoch=25/40, Step=1624/4124, loss=1.197619, time_each_step=0.31s, eta=5:28:56\n",
      "2021-05-06 07:45:08 [INFO]\t[TRAIN] Epoch=25/40, Step=1824/4124, loss=1.108881, time_each_step=0.3s, eta=5:27:43\n",
      "2021-05-06 07:46:09 [INFO]\t[TRAIN] Epoch=25/40, Step=2024/4124, loss=0.699274, time_each_step=0.3s, eta=5:26:49\n",
      "2021-05-06 07:47:10 [INFO]\t[TRAIN] Epoch=25/40, Step=2224/4124, loss=0.970596, time_each_step=0.3s, eta=5:25:50\n",
      "2021-05-06 07:48:10 [INFO]\t[TRAIN] Epoch=25/40, Step=2424/4124, loss=0.603276, time_each_step=0.3s, eta=5:24:44\n",
      "2021-05-06 07:49:11 [INFO]\t[TRAIN] Epoch=25/40, Step=2624/4124, loss=0.469582, time_each_step=0.31s, eta=5:23:53\n",
      "2021-05-06 07:50:12 [INFO]\t[TRAIN] Epoch=25/40, Step=2824/4124, loss=0.609043, time_each_step=0.3s, eta=5:22:43\n",
      "2021-05-06 07:51:13 [INFO]\t[TRAIN] Epoch=25/40, Step=3024/4124, loss=0.784057, time_each_step=0.3s, eta=5:21:46\n",
      "2021-05-06 07:52:14 [INFO]\t[TRAIN] Epoch=25/40, Step=3224/4124, loss=0.468992, time_each_step=0.3s, eta=5:20:42\n",
      "2021-05-06 07:53:15 [INFO]\t[TRAIN] Epoch=25/40, Step=3424/4124, loss=1.012756, time_each_step=0.3s, eta=5:19:44\n",
      "2021-05-06 07:54:16 [INFO]\t[TRAIN] Epoch=25/40, Step=3624/4124, loss=0.675251, time_each_step=0.31s, eta=5:18:44\n",
      "2021-05-06 07:55:17 [INFO]\t[TRAIN] Epoch=25/40, Step=3824/4124, loss=0.806631, time_each_step=0.31s, eta=5:17:43\n",
      "2021-05-06 07:56:18 [INFO]\t[TRAIN] Epoch=25/40, Step=4024/4124, loss=0.56117, time_each_step=0.3s, eta=5:16:41\n",
      "2021-05-06 07:56:48 [INFO]\t[TRAIN] Epoch 25 finished, loss=0.662678 .\n",
      "2021-05-06 07:57:24 [INFO]\t[TRAIN] Epoch=26/40, Step=100/4124, loss=0.918453, time_each_step=0.31s, eta=5:15:56\n",
      "2021-05-06 07:58:25 [INFO]\t[TRAIN] Epoch=26/40, Step=300/4124, loss=0.436643, time_each_step=0.3s, eta=5:14:49\n",
      "2021-05-06 07:59:26 [INFO]\t[TRAIN] Epoch=26/40, Step=500/4124, loss=0.681139, time_each_step=0.3s, eta=5:13:45\n",
      "2021-05-06 08:00:27 [INFO]\t[TRAIN] Epoch=26/40, Step=700/4124, loss=0.722752, time_each_step=0.3s, eta=5:12:44\n",
      "2021-05-06 08:01:28 [INFO]\t[TRAIN] Epoch=26/40, Step=900/4124, loss=0.253226, time_each_step=0.3s, eta=5:11:28\n",
      "2021-05-06 08:02:28 [INFO]\t[TRAIN] Epoch=26/40, Step=1100/4124, loss=0.707818, time_each_step=0.3s, eta=5:10:37\n",
      "2021-05-06 08:03:29 [INFO]\t[TRAIN] Epoch=26/40, Step=1300/4124, loss=0.43933, time_each_step=0.31s, eta=5:9:48\n",
      "2021-05-06 08:04:31 [INFO]\t[TRAIN] Epoch=26/40, Step=1500/4124, loss=0.607294, time_each_step=0.31s, eta=5:8:50\n",
      "2021-05-06 08:05:31 [INFO]\t[TRAIN] Epoch=26/40, Step=1700/4124, loss=0.707885, time_each_step=0.31s, eta=5:7:54\n",
      "2021-05-06 08:06:32 [INFO]\t[TRAIN] Epoch=26/40, Step=1900/4124, loss=0.54023, time_each_step=0.31s, eta=5:6:45\n",
      "2021-05-06 08:07:34 [INFO]\t[TRAIN] Epoch=26/40, Step=2100/4124, loss=0.453793, time_each_step=0.3s, eta=5:5:41\n",
      "2021-05-06 08:08:34 [INFO]\t[TRAIN] Epoch=26/40, Step=2300/4124, loss=0.804161, time_each_step=0.3s, eta=5:4:38\n",
      "2021-05-06 08:09:35 [INFO]\t[TRAIN] Epoch=26/40, Step=2500/4124, loss=0.513733, time_each_step=0.3s, eta=5:3:39\n",
      "2021-05-06 08:10:36 [INFO]\t[TRAIN] Epoch=26/40, Step=2700/4124, loss=0.793641, time_each_step=0.3s, eta=5:2:38\n",
      "2021-05-06 08:11:37 [INFO]\t[TRAIN] Epoch=26/40, Step=2900/4124, loss=0.584705, time_each_step=0.3s, eta=5:1:39\n",
      "2021-05-06 08:12:38 [INFO]\t[TRAIN] Epoch=26/40, Step=3100/4124, loss=0.986287, time_each_step=0.31s, eta=5:0:45\n",
      "2021-05-06 08:13:39 [INFO]\t[TRAIN] Epoch=26/40, Step=3300/4124, loss=1.283416, time_each_step=0.3s, eta=4:59:37\n",
      "2021-05-06 08:14:39 [INFO]\t[TRAIN] Epoch=26/40, Step=3500/4124, loss=0.490379, time_each_step=0.3s, eta=4:58:35\n",
      "2021-05-06 08:15:40 [INFO]\t[TRAIN] Epoch=26/40, Step=3700/4124, loss=0.65019, time_each_step=0.3s, eta=4:57:35\n",
      "2021-05-06 08:16:41 [INFO]\t[TRAIN] Epoch=26/40, Step=3900/4124, loss=0.685896, time_each_step=0.3s, eta=4:56:34\n",
      "2021-05-06 08:17:42 [INFO]\t[TRAIN] Epoch=26/40, Step=4100/4124, loss=1.128438, time_each_step=0.3s, eta=4:55:34\n",
      "2021-05-06 08:17:49 [INFO]\t[TRAIN] Epoch 26 finished, loss=0.649585 .\n",
      "2021-05-06 08:17:49 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 08:17:56 [INFO]\t[EVAL] Finished, Epoch=26, miou=0.493243, category_iou=[0.48210104 0.67885767 0.46866277 0.34334992], oacc=0.668712, category_acc=[0.63176109 0.86533776 0.57262564 0.54808406], kappa=0.550233, category_F1-score=[0.65056434 0.80871379 0.638217   0.51118464] .\n",
      "2021-05-06 08:18:00 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-05-06 08:18:04 [INFO]\tModel saved in output/deeplab/epoch_26.\n",
      "2021-05-06 08:18:04 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_26, miou=0.4932428532077531\n",
      "2021-05-06 08:19:01 [INFO]\t[TRAIN] Epoch=27/40, Step=176/4124, loss=0.413107, time_each_step=0.3s, eta=4:54:54\n",
      "2021-05-06 08:20:02 [INFO]\t[TRAIN] Epoch=27/40, Step=376/4124, loss=0.306186, time_each_step=0.3s, eta=4:53:49\n",
      "2021-05-06 08:21:02 [INFO]\t[TRAIN] Epoch=27/40, Step=576/4124, loss=0.57355, time_each_step=0.3s, eta=4:52:51\n",
      "2021-05-06 08:22:03 [INFO]\t[TRAIN] Epoch=27/40, Step=776/4124, loss=1.104769, time_each_step=0.31s, eta=4:51:57\n",
      "2021-05-06 08:23:04 [INFO]\t[TRAIN] Epoch=27/40, Step=976/4124, loss=0.544974, time_each_step=0.3s, eta=4:50:48\n",
      "2021-05-06 08:24:05 [INFO]\t[TRAIN] Epoch=27/40, Step=1176/4124, loss=0.729487, time_each_step=0.3s, eta=4:49:43\n",
      "2021-05-06 08:25:06 [INFO]\t[TRAIN] Epoch=27/40, Step=1376/4124, loss=0.818721, time_each_step=0.31s, eta=4:49:1\n",
      "2021-05-06 08:26:07 [INFO]\t[TRAIN] Epoch=27/40, Step=1576/4124, loss=0.341525, time_each_step=0.3s, eta=4:47:47\n",
      "2021-05-06 08:27:08 [INFO]\t[TRAIN] Epoch=27/40, Step=1776/4124, loss=0.500401, time_each_step=0.3s, eta=4:46:49\n",
      "2021-05-06 08:28:08 [INFO]\t[TRAIN] Epoch=27/40, Step=1976/4124, loss=0.826932, time_each_step=0.3s, eta=4:45:46\n",
      "2021-05-06 08:29:09 [INFO]\t[TRAIN] Epoch=27/40, Step=2176/4124, loss=1.059703, time_each_step=0.3s, eta=4:44:46\n",
      "2021-05-06 08:30:10 [INFO]\t[TRAIN] Epoch=27/40, Step=2376/4124, loss=0.658405, time_each_step=0.3s, eta=4:43:43\n",
      "2021-05-06 08:31:11 [INFO]\t[TRAIN] Epoch=27/40, Step=2576/4124, loss=0.624228, time_each_step=0.3s, eta=4:42:41\n",
      "2021-05-06 08:32:12 [INFO]\t[TRAIN] Epoch=27/40, Step=2776/4124, loss=0.367767, time_each_step=0.3s, eta=4:41:40\n",
      "2021-05-06 08:33:12 [INFO]\t[TRAIN] Epoch=27/40, Step=2976/4124, loss=0.782817, time_each_step=0.3s, eta=4:40:40\n",
      "2021-05-06 08:34:13 [INFO]\t[TRAIN] Epoch=27/40, Step=3176/4124, loss=0.472783, time_each_step=0.3s, eta=4:39:38\n",
      "2021-05-06 08:35:14 [INFO]\t[TRAIN] Epoch=27/40, Step=3376/4124, loss=0.806279, time_each_step=0.3s, eta=4:38:40\n",
      "2021-05-06 08:36:15 [INFO]\t[TRAIN] Epoch=27/40, Step=3576/4124, loss=0.579999, time_each_step=0.3s, eta=4:37:39\n",
      "2021-05-06 08:37:16 [INFO]\t[TRAIN] Epoch=27/40, Step=3776/4124, loss=0.835545, time_each_step=0.3s, eta=4:36:39\n",
      "2021-05-06 08:38:17 [INFO]\t[TRAIN] Epoch=27/40, Step=3976/4124, loss=0.470189, time_each_step=0.3s, eta=4:35:38\n",
      "2021-05-06 08:39:02 [INFO]\t[TRAIN] Epoch 27 finished, loss=0.637812 .\n",
      "2021-05-06 08:39:23 [INFO]\t[TRAIN] Epoch=28/40, Step=52/4124, loss=0.334729, time_each_step=0.31s, eta=4:34:31\n",
      "2021-05-06 08:40:24 [INFO]\t[TRAIN] Epoch=28/40, Step=252/4124, loss=0.650933, time_each_step=0.3s, eta=4:32:46\n",
      "2021-05-06 08:41:25 [INFO]\t[TRAIN] Epoch=28/40, Step=452/4124, loss=0.70389, time_each_step=0.3s, eta=4:31:50\n",
      "2021-05-06 08:42:26 [INFO]\t[TRAIN] Epoch=28/40, Step=652/4124, loss=1.040172, time_each_step=0.3s, eta=4:30:49\n",
      "2021-05-06 08:43:27 [INFO]\t[TRAIN] Epoch=28/40, Step=852/4124, loss=0.644157, time_each_step=0.3s, eta=4:29:47\n",
      "2021-05-06 08:44:27 [INFO]\t[TRAIN] Epoch=28/40, Step=1052/4124, loss=0.711169, time_each_step=0.3s, eta=4:28:50\n",
      "2021-05-06 08:45:28 [INFO]\t[TRAIN] Epoch=28/40, Step=1252/4124, loss=0.613406, time_each_step=0.31s, eta=4:28:8\n",
      "2021-05-06 08:46:30 [INFO]\t[TRAIN] Epoch=28/40, Step=1452/4124, loss=0.45232, time_each_step=0.3s, eta=4:26:51\n",
      "2021-05-06 08:47:31 [INFO]\t[TRAIN] Epoch=28/40, Step=1652/4124, loss=0.657355, time_each_step=0.3s, eta=4:25:46\n",
      "2021-05-06 08:48:32 [INFO]\t[TRAIN] Epoch=28/40, Step=1852/4124, loss=0.618032, time_each_step=0.31s, eta=4:24:54\n",
      "2021-05-06 08:49:33 [INFO]\t[TRAIN] Epoch=28/40, Step=2052/4124, loss=0.613136, time_each_step=0.3s, eta=4:23:47\n",
      "2021-05-06 08:50:34 [INFO]\t[TRAIN] Epoch=28/40, Step=2252/4124, loss=0.625288, time_each_step=0.31s, eta=4:22:50\n",
      "2021-05-06 08:51:34 [INFO]\t[TRAIN] Epoch=28/40, Step=2452/4124, loss=0.597337, time_each_step=0.3s, eta=4:21:41\n",
      "2021-05-06 08:52:35 [INFO]\t[TRAIN] Epoch=28/40, Step=2652/4124, loss=0.844209, time_each_step=0.31s, eta=4:20:48\n",
      "2021-05-06 08:53:36 [INFO]\t[TRAIN] Epoch=28/40, Step=2852/4124, loss=0.526693, time_each_step=0.3s, eta=4:19:44\n",
      "2021-05-06 08:54:37 [INFO]\t[TRAIN] Epoch=28/40, Step=3052/4124, loss=0.519286, time_each_step=0.31s, eta=4:18:46\n",
      "2021-05-06 08:55:38 [INFO]\t[TRAIN] Epoch=28/40, Step=3252/4124, loss=0.725055, time_each_step=0.31s, eta=4:17:44\n",
      "2021-05-06 08:56:39 [INFO]\t[TRAIN] Epoch=28/40, Step=3452/4124, loss=1.067688, time_each_step=0.3s, eta=4:16:41\n",
      "2021-05-06 08:57:40 [INFO]\t[TRAIN] Epoch=28/40, Step=3652/4124, loss=0.859697, time_each_step=0.3s, eta=4:15:40\n",
      "2021-05-06 08:58:41 [INFO]\t[TRAIN] Epoch=28/40, Step=3852/4124, loss=0.847976, time_each_step=0.31s, eta=4:14:41\n",
      "2021-05-06 08:59:42 [INFO]\t[TRAIN] Epoch=28/40, Step=4052/4124, loss=0.417296, time_each_step=0.3s, eta=4:13:39\n",
      "2021-05-06 09:00:03 [INFO]\t[TRAIN] Epoch 28 finished, loss=0.629853 .\n",
      "2021-05-06 09:00:03 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 09:00:10 [INFO]\t[EVAL] Finished, Epoch=28, miou=0.460508, category_iou=[0.45883987 0.67323557 0.44569906 0.26425653], oacc=0.638504, category_acc=[0.62994229 0.82760335 0.58537305 0.41970092], kappa=0.508645, category_F1-score=[0.62904762 0.80471105 0.61658622 0.41804258] .\n",
      "2021-05-06 09:00:14 [INFO]\tModel saved in output/deeplab/epoch_28.\n",
      "2021-05-06 09:00:14 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_26, miou=0.4932428532077531\n",
      "2021-05-06 09:00:56 [INFO]\t[TRAIN] Epoch=29/40, Step=128/4124, loss=0.688076, time_each_step=0.3s, eta=4:12:30\n",
      "2021-05-06 09:01:57 [INFO]\t[TRAIN] Epoch=29/40, Step=328/4124, loss=0.59457, time_each_step=0.3s, eta=4:11:33\n",
      "2021-05-06 09:02:58 [INFO]\t[TRAIN] Epoch=29/40, Step=528/4124, loss=0.683086, time_each_step=0.3s, eta=4:10:22\n",
      "2021-05-06 09:03:58 [INFO]\t[TRAIN] Epoch=29/40, Step=728/4124, loss=0.775339, time_each_step=0.31s, eta=4:9:42\n",
      "2021-05-06 09:04:59 [INFO]\t[TRAIN] Epoch=29/40, Step=928/4124, loss=0.500538, time_each_step=0.3s, eta=4:8:30\n",
      "2021-05-06 09:06:00 [INFO]\t[TRAIN] Epoch=29/40, Step=1128/4124, loss=0.457398, time_each_step=0.3s, eta=4:7:33\n",
      "2021-05-06 09:07:01 [INFO]\t[TRAIN] Epoch=29/40, Step=1328/4124, loss=0.442921, time_each_step=0.3s, eta=4:6:25\n",
      "2021-05-06 09:08:02 [INFO]\t[TRAIN] Epoch=29/40, Step=1528/4124, loss=0.527858, time_each_step=0.31s, eta=4:5:41\n",
      "2021-05-06 09:09:03 [INFO]\t[TRAIN] Epoch=29/40, Step=1728/4124, loss=0.348067, time_each_step=0.3s, eta=4:4:29\n",
      "2021-05-06 09:10:04 [INFO]\t[TRAIN] Epoch=29/40, Step=1928/4124, loss=0.269484, time_each_step=0.3s, eta=4:3:27\n",
      "2021-05-06 09:11:04 [INFO]\t[TRAIN] Epoch=29/40, Step=2128/4124, loss=0.528741, time_each_step=0.3s, eta=4:2:25\n",
      "2021-05-06 09:12:05 [INFO]\t[TRAIN] Epoch=29/40, Step=2328/4124, loss=0.513685, time_each_step=0.3s, eta=4:1:27\n",
      "2021-05-06 09:13:06 [INFO]\t[TRAIN] Epoch=29/40, Step=2528/4124, loss=0.560541, time_each_step=0.31s, eta=4:0:37\n",
      "2021-05-06 09:14:07 [INFO]\t[TRAIN] Epoch=29/40, Step=2728/4124, loss=0.403905, time_each_step=0.3s, eta=3:59:26\n",
      "2021-05-06 09:15:08 [INFO]\t[TRAIN] Epoch=29/40, Step=2928/4124, loss=0.719384, time_each_step=0.31s, eta=3:58:33\n",
      "2021-05-06 09:16:08 [INFO]\t[TRAIN] Epoch=29/40, Step=3128/4124, loss=0.325695, time_each_step=0.3s, eta=3:57:24\n",
      "2021-05-06 09:17:09 [INFO]\t[TRAIN] Epoch=29/40, Step=3328/4124, loss=0.870478, time_each_step=0.3s, eta=3:56:23\n",
      "2021-05-06 09:18:10 [INFO]\t[TRAIN] Epoch=29/40, Step=3528/4124, loss=0.321327, time_each_step=0.31s, eta=3:55:25\n",
      "2021-05-06 09:19:11 [INFO]\t[TRAIN] Epoch=29/40, Step=3728/4124, loss=0.471871, time_each_step=0.3s, eta=3:54:22\n",
      "2021-05-06 09:20:12 [INFO]\t[TRAIN] Epoch=29/40, Step=3928/4124, loss=0.397007, time_each_step=0.31s, eta=3:53:22\n",
      "2021-05-06 09:21:11 [INFO]\t[TRAIN] Epoch 29 finished, loss=0.616965 .\n",
      "2021-05-06 09:21:16 [INFO]\t[TRAIN] Epoch=30/40, Step=4/4124, loss=0.269275, time_each_step=0.49s, eta=4:4:25\n",
      "2021-05-06 09:22:17 [INFO]\t[TRAIN] Epoch=30/40, Step=204/4124, loss=0.559437, time_each_step=0.3s, eta=3:50:12\n",
      "2021-05-06 09:23:18 [INFO]\t[TRAIN] Epoch=30/40, Step=404/4124, loss=0.726578, time_each_step=0.3s, eta=3:49:21\n",
      "2021-05-06 09:24:19 [INFO]\t[TRAIN] Epoch=30/40, Step=604/4124, loss=0.62308, time_each_step=0.3s, eta=3:48:18\n",
      "2021-05-06 09:25:20 [INFO]\t[TRAIN] Epoch=30/40, Step=804/4124, loss=0.771311, time_each_step=0.3s, eta=3:47:24\n",
      "2021-05-06 09:26:20 [INFO]\t[TRAIN] Epoch=30/40, Step=1004/4124, loss=0.533958, time_each_step=0.31s, eta=3:46:31\n",
      "2021-05-06 09:27:21 [INFO]\t[TRAIN] Epoch=30/40, Step=1204/4124, loss=0.542634, time_each_step=0.3s, eta=3:45:24\n",
      "2021-05-06 09:28:22 [INFO]\t[TRAIN] Epoch=30/40, Step=1404/4124, loss=0.698977, time_each_step=0.31s, eta=3:44:25\n",
      "2021-05-06 09:29:23 [INFO]\t[TRAIN] Epoch=30/40, Step=1604/4124, loss=0.983849, time_each_step=0.3s, eta=3:43:20\n",
      "2021-05-06 09:30:24 [INFO]\t[TRAIN] Epoch=30/40, Step=1804/4124, loss=0.705497, time_each_step=0.31s, eta=3:42:25\n",
      "2021-05-06 09:31:25 [INFO]\t[TRAIN] Epoch=30/40, Step=2004/4124, loss=0.359667, time_each_step=0.3s, eta=3:41:22\n",
      "2021-05-06 09:32:26 [INFO]\t[TRAIN] Epoch=30/40, Step=2204/4124, loss=0.552512, time_each_step=0.3s, eta=3:40:18\n",
      "2021-05-06 09:33:26 [INFO]\t[TRAIN] Epoch=30/40, Step=2404/4124, loss=0.655025, time_each_step=0.3s, eta=3:39:17\n",
      "2021-05-06 09:34:27 [INFO]\t[TRAIN] Epoch=30/40, Step=2604/4124, loss=0.624026, time_each_step=0.31s, eta=3:38:23\n",
      "2021-05-06 09:35:28 [INFO]\t[TRAIN] Epoch=30/40, Step=2804/4124, loss=0.569189, time_each_step=0.3s, eta=3:37:13\n",
      "2021-05-06 09:36:29 [INFO]\t[TRAIN] Epoch=30/40, Step=3004/4124, loss=0.728337, time_each_step=0.31s, eta=3:36:25\n",
      "2021-05-06 09:37:30 [INFO]\t[TRAIN] Epoch=30/40, Step=3204/4124, loss=0.555179, time_each_step=0.3s, eta=3:35:14\n",
      "2021-05-06 09:38:31 [INFO]\t[TRAIN] Epoch=30/40, Step=3404/4124, loss=0.681138, time_each_step=0.3s, eta=3:34:14\n",
      "2021-05-06 09:39:32 [INFO]\t[TRAIN] Epoch=30/40, Step=3604/4124, loss=0.474029, time_each_step=0.3s, eta=3:33:13\n",
      "2021-05-06 09:40:33 [INFO]\t[TRAIN] Epoch=30/40, Step=3804/4124, loss=0.474174, time_each_step=0.3s, eta=3:32:12\n",
      "2021-05-06 09:41:33 [INFO]\t[TRAIN] Epoch=30/40, Step=4004/4124, loss=0.578473, time_each_step=0.3s, eta=3:31:12\n",
      "2021-05-06 09:42:09 [INFO]\t[TRAIN] Epoch 30 finished, loss=0.611155 .\n",
      "2021-05-06 09:42:09 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 09:42:17 [INFO]\t[EVAL] Finished, Epoch=30, miou=0.491902, category_iou=[0.51668831 0.65580378 0.49520791 0.29990859], oacc=0.670414, category_acc=[0.67024979 0.78206336 0.68421631 0.47122418], kappa=0.548943, category_F1-score=[0.6813375  0.79212741 0.66239338 0.46143027] .\n",
      "2021-05-06 09:42:21 [INFO]\tModel saved in output/deeplab/epoch_30.\n",
      "2021-05-06 09:42:21 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_26, miou=0.4932428532077531\n",
      "2021-05-06 09:43:00 [INFO]\t[TRAIN] Epoch=31/40, Step=80/4124, loss=0.58094, time_each_step=0.3s, eta=3:30:10\n",
      "2021-05-06 09:44:00 [INFO]\t[TRAIN] Epoch=31/40, Step=280/4124, loss=0.56178, time_each_step=0.3s, eta=3:29:4\n",
      "2021-05-06 09:45:01 [INFO]\t[TRAIN] Epoch=31/40, Step=480/4124, loss=0.857701, time_each_step=0.31s, eta=3:28:16\n",
      "2021-05-06 09:46:02 [INFO]\t[TRAIN] Epoch=31/40, Step=680/4124, loss=0.301822, time_each_step=0.31s, eta=3:27:12\n",
      "2021-05-06 09:47:03 [INFO]\t[TRAIN] Epoch=31/40, Step=880/4124, loss=0.900772, time_each_step=0.3s, eta=3:25:55\n",
      "2021-05-06 09:48:04 [INFO]\t[TRAIN] Epoch=31/40, Step=1080/4124, loss=0.226711, time_each_step=0.3s, eta=3:25:8\n",
      "2021-05-06 09:49:05 [INFO]\t[TRAIN] Epoch=31/40, Step=1280/4124, loss=0.433687, time_each_step=0.31s, eta=3:24:11\n",
      "2021-05-06 09:50:06 [INFO]\t[TRAIN] Epoch=31/40, Step=1480/4124, loss=0.795216, time_each_step=0.31s, eta=3:23:7\n",
      "2021-05-06 09:51:06 [INFO]\t[TRAIN] Epoch=31/40, Step=1680/4124, loss=0.453988, time_each_step=0.31s, eta=3:22:9\n",
      "2021-05-06 09:52:07 [INFO]\t[TRAIN] Epoch=31/40, Step=1880/4124, loss=0.31593, time_each_step=0.3s, eta=3:21:3\n",
      "2021-05-06 09:53:08 [INFO]\t[TRAIN] Epoch=31/40, Step=2080/4124, loss=0.513548, time_each_step=0.3s, eta=3:20:2\n",
      "2021-05-06 09:54:09 [INFO]\t[TRAIN] Epoch=31/40, Step=2280/4124, loss=0.510812, time_each_step=0.31s, eta=3:19:5\n",
      "2021-05-06 09:55:09 [INFO]\t[TRAIN] Epoch=31/40, Step=2480/4124, loss=0.553448, time_each_step=0.3s, eta=3:17:58\n",
      "2021-05-06 09:56:10 [INFO]\t[TRAIN] Epoch=31/40, Step=2680/4124, loss=0.516876, time_each_step=0.3s, eta=3:16:58\n",
      "2021-05-06 09:57:11 [INFO]\t[TRAIN] Epoch=31/40, Step=2880/4124, loss=0.782898, time_each_step=0.3s, eta=3:15:57\n",
      "2021-05-06 09:58:12 [INFO]\t[TRAIN] Epoch=31/40, Step=3080/4124, loss=0.690504, time_each_step=0.3s, eta=3:14:59\n",
      "2021-05-06 09:59:13 [INFO]\t[TRAIN] Epoch=31/40, Step=3280/4124, loss=0.470071, time_each_step=0.3s, eta=3:13:56\n",
      "2021-05-06 10:00:14 [INFO]\t[TRAIN] Epoch=31/40, Step=3480/4124, loss=0.511212, time_each_step=0.3s, eta=3:12:56\n",
      "2021-05-06 10:01:15 [INFO]\t[TRAIN] Epoch=31/40, Step=3680/4124, loss=0.477696, time_each_step=0.3s, eta=3:11:56\n",
      "2021-05-06 10:02:15 [INFO]\t[TRAIN] Epoch=31/40, Step=3880/4124, loss=0.492736, time_each_step=0.3s, eta=3:10:55\n",
      "2021-05-06 10:03:16 [INFO]\t[TRAIN] Epoch=31/40, Step=4080/4124, loss=0.752242, time_each_step=0.3s, eta=3:9:54\n",
      "2021-05-06 10:03:29 [INFO]\t[TRAIN] Epoch 31 finished, loss=0.598226 .\n",
      "2021-05-06 10:04:21 [INFO]\t[TRAIN] Epoch=32/40, Step=156/4124, loss=0.247374, time_each_step=0.3s, eta=3:10:12\n",
      "2021-05-06 10:05:22 [INFO]\t[TRAIN] Epoch=32/40, Step=356/4124, loss=0.464614, time_each_step=0.31s, eta=3:9:25\n",
      "2021-05-06 10:06:23 [INFO]\t[TRAIN] Epoch=32/40, Step=556/4124, loss=0.576848, time_each_step=0.3s, eta=3:8:2\n",
      "2021-05-06 10:07:24 [INFO]\t[TRAIN] Epoch=32/40, Step=756/4124, loss=1.288109, time_each_step=0.31s, eta=3:7:11\n",
      "2021-05-06 10:08:25 [INFO]\t[TRAIN] Epoch=32/40, Step=956/4124, loss=0.654755, time_each_step=0.3s, eta=3:5:59\n",
      "2021-05-06 10:09:25 [INFO]\t[TRAIN] Epoch=32/40, Step=1156/4124, loss=0.453563, time_each_step=0.31s, eta=3:5:9\n",
      "2021-05-06 10:10:26 [INFO]\t[TRAIN] Epoch=32/40, Step=1356/4124, loss=0.768174, time_each_step=0.3s, eta=3:4:2\n",
      "2021-05-06 10:11:27 [INFO]\t[TRAIN] Epoch=32/40, Step=1556/4124, loss=0.686318, time_each_step=0.3s, eta=3:3:2\n",
      "2021-05-06 10:12:28 [INFO]\t[TRAIN] Epoch=32/40, Step=1756/4124, loss=0.353492, time_each_step=0.31s, eta=3:2:10\n",
      "2021-05-06 10:13:29 [INFO]\t[TRAIN] Epoch=32/40, Step=1956/4124, loss=0.530462, time_each_step=0.3s, eta=3:1:1\n",
      "2021-05-06 10:14:29 [INFO]\t[TRAIN] Epoch=32/40, Step=2156/4124, loss=0.494864, time_each_step=0.3s, eta=2:59:59\n",
      "2021-05-06 10:15:30 [INFO]\t[TRAIN] Epoch=32/40, Step=2356/4124, loss=0.563155, time_each_step=0.3s, eta=2:58:59\n",
      "2021-05-06 10:16:31 [INFO]\t[TRAIN] Epoch=32/40, Step=2556/4124, loss=0.415589, time_each_step=0.3s, eta=2:57:58\n",
      "2021-05-06 10:17:32 [INFO]\t[TRAIN] Epoch=32/40, Step=2756/4124, loss=0.436091, time_each_step=0.3s, eta=2:56:59\n",
      "2021-05-06 10:18:33 [INFO]\t[TRAIN] Epoch=32/40, Step=2956/4124, loss=0.79338, time_each_step=0.3s, eta=2:55:55\n",
      "2021-05-06 10:19:34 [INFO]\t[TRAIN] Epoch=32/40, Step=3156/4124, loss=0.771759, time_each_step=0.3s, eta=2:54:58\n",
      "2021-05-06 10:20:35 [INFO]\t[TRAIN] Epoch=32/40, Step=3356/4124, loss=0.610235, time_each_step=0.3s, eta=2:53:54\n",
      "2021-05-06 10:21:35 [INFO]\t[TRAIN] Epoch=32/40, Step=3556/4124, loss=0.447884, time_each_step=0.3s, eta=2:52:55\n",
      "2021-05-06 10:22:36 [INFO]\t[TRAIN] Epoch=32/40, Step=3756/4124, loss=0.544145, time_each_step=0.3s, eta=2:51:55\n",
      "2021-05-06 10:23:37 [INFO]\t[TRAIN] Epoch=32/40, Step=3956/4124, loss=0.663995, time_each_step=0.31s, eta=2:50:55\n",
      "2021-05-06 10:24:28 [INFO]\t[TRAIN] Epoch 32 finished, loss=0.59128 .\n",
      "2021-05-06 10:24:28 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 10:24:35 [INFO]\t[EVAL] Finished, Epoch=32, miou=0.48675, category_iou=[0.46109105 0.66686967 0.45085229 0.36818663], oacc=0.663721, category_acc=[0.70949505 0.78756277 0.5745395  0.51185071], kappa=0.545558, category_F1-score=[0.63115991 0.80014615 0.62149992 0.53821112] .\n",
      "2021-05-06 10:24:39 [INFO]\tModel saved in output/deeplab/epoch_32.\n",
      "2021-05-06 10:24:39 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_26, miou=0.4932428532077531\n",
      "2021-05-06 10:24:53 [INFO]\t[TRAIN] Epoch=33/40, Step=32/4124, loss=0.716825, time_each_step=0.33s, eta=2:50:3\n",
      "2021-05-06 10:25:53 [INFO]\t[TRAIN] Epoch=33/40, Step=232/4124, loss=0.693104, time_each_step=0.3s, eta=2:47:18\n",
      "2021-05-06 10:26:54 [INFO]\t[TRAIN] Epoch=33/40, Step=432/4124, loss=0.374214, time_each_step=0.3s, eta=2:46:8\n",
      "2021-05-06 10:27:54 [INFO]\t[TRAIN] Epoch=33/40, Step=632/4124, loss=0.436012, time_each_step=0.3s, eta=2:45:7\n",
      "2021-05-06 10:28:55 [INFO]\t[TRAIN] Epoch=33/40, Step=832/4124, loss=0.437231, time_each_step=0.31s, eta=2:44:39\n",
      "2021-05-06 10:29:56 [INFO]\t[TRAIN] Epoch=33/40, Step=1032/4124, loss=0.558458, time_each_step=0.3s, eta=2:43:15\n",
      "2021-05-06 10:30:57 [INFO]\t[TRAIN] Epoch=33/40, Step=1232/4124, loss=0.790358, time_each_step=0.3s, eta=2:42:12\n",
      "2021-05-06 10:31:58 [INFO]\t[TRAIN] Epoch=33/40, Step=1432/4124, loss=0.449647, time_each_step=0.3s, eta=2:41:11\n",
      "2021-05-06 10:32:59 [INFO]\t[TRAIN] Epoch=33/40, Step=1632/4124, loss=0.456181, time_each_step=0.3s, eta=2:40:13\n",
      "2021-05-06 10:34:00 [INFO]\t[TRAIN] Epoch=33/40, Step=1832/4124, loss=0.409914, time_each_step=0.3s, eta=2:39:9\n",
      "2021-05-06 10:35:00 [INFO]\t[TRAIN] Epoch=33/40, Step=2032/4124, loss=0.479992, time_each_step=0.3s, eta=2:38:8\n",
      "2021-05-06 10:36:01 [INFO]\t[TRAIN] Epoch=33/40, Step=2232/4124, loss=0.759307, time_each_step=0.31s, eta=2:37:13\n",
      "2021-05-06 10:37:02 [INFO]\t[TRAIN] Epoch=33/40, Step=2432/4124, loss=0.58274, time_each_step=0.3s, eta=2:36:6\n",
      "2021-05-06 10:38:03 [INFO]\t[TRAIN] Epoch=33/40, Step=2632/4124, loss=0.57734, time_each_step=0.31s, eta=2:35:20\n",
      "2021-05-06 10:39:04 [INFO]\t[TRAIN] Epoch=33/40, Step=2832/4124, loss=0.401183, time_each_step=0.3s, eta=2:34:3\n",
      "2021-05-06 10:40:05 [INFO]\t[TRAIN] Epoch=33/40, Step=3032/4124, loss=1.011245, time_each_step=0.3s, eta=2:33:6\n",
      "2021-05-06 10:41:06 [INFO]\t[TRAIN] Epoch=33/40, Step=3232/4124, loss=0.44328, time_each_step=0.31s, eta=2:32:6\n",
      "2021-05-06 10:42:07 [INFO]\t[TRAIN] Epoch=33/40, Step=3432/4124, loss=0.688594, time_each_step=0.31s, eta=2:31:6\n",
      "2021-05-06 10:43:08 [INFO]\t[TRAIN] Epoch=33/40, Step=3632/4124, loss=0.400432, time_each_step=0.31s, eta=2:30:5\n",
      "2021-05-06 10:44:09 [INFO]\t[TRAIN] Epoch=33/40, Step=3832/4124, loss=0.871517, time_each_step=0.31s, eta=2:29:3\n",
      "2021-05-06 10:45:09 [INFO]\t[TRAIN] Epoch=33/40, Step=4032/4124, loss=0.513018, time_each_step=0.3s, eta=2:28:1\n",
      "2021-05-06 10:45:37 [INFO]\t[TRAIN] Epoch 33 finished, loss=0.581872 .\n",
      "2021-05-06 10:46:14 [INFO]\t[TRAIN] Epoch=34/40, Step=108/4124, loss=0.44845, time_each_step=0.31s, eta=2:27:19\n",
      "2021-05-06 10:47:15 [INFO]\t[TRAIN] Epoch=34/40, Step=308/4124, loss=0.508188, time_each_step=0.31s, eta=2:26:9\n",
      "2021-05-06 10:48:16 [INFO]\t[TRAIN] Epoch=34/40, Step=508/4124, loss=0.598741, time_each_step=0.3s, eta=2:24:54\n",
      "2021-05-06 10:49:17 [INFO]\t[TRAIN] Epoch=34/40, Step=708/4124, loss=0.476223, time_each_step=0.3s, eta=2:23:54\n",
      "2021-05-06 10:50:18 [INFO]\t[TRAIN] Epoch=34/40, Step=908/4124, loss=0.962085, time_each_step=0.3s, eta=2:22:50\n",
      "2021-05-06 10:51:19 [INFO]\t[TRAIN] Epoch=34/40, Step=1108/4124, loss=0.630236, time_each_step=0.3s, eta=2:21:47\n",
      "2021-05-06 10:52:20 [INFO]\t[TRAIN] Epoch=34/40, Step=1308/4124, loss=0.481464, time_each_step=0.31s, eta=2:21:5\n",
      "2021-05-06 10:53:21 [INFO]\t[TRAIN] Epoch=34/40, Step=1508/4124, loss=0.838853, time_each_step=0.3s, eta=2:19:47\n",
      "2021-05-06 10:54:22 [INFO]\t[TRAIN] Epoch=34/40, Step=1708/4124, loss=0.914134, time_each_step=0.3s, eta=2:18:47\n",
      "2021-05-06 10:55:22 [INFO]\t[TRAIN] Epoch=34/40, Step=1908/4124, loss=0.655988, time_each_step=0.3s, eta=2:17:48\n",
      "2021-05-06 10:56:24 [INFO]\t[TRAIN] Epoch=34/40, Step=2108/4124, loss=0.75417, time_each_step=0.31s, eta=2:16:53\n",
      "2021-05-06 10:57:24 [INFO]\t[TRAIN] Epoch=34/40, Step=2308/4124, loss=0.562681, time_each_step=0.3s, eta=2:15:44\n",
      "2021-05-06 10:58:25 [INFO]\t[TRAIN] Epoch=34/40, Step=2508/4124, loss=0.482241, time_each_step=0.3s, eta=2:14:44\n",
      "2021-05-06 10:59:26 [INFO]\t[TRAIN] Epoch=34/40, Step=2708/4124, loss=0.804994, time_each_step=0.3s, eta=2:13:45\n",
      "2021-05-06 11:00:27 [INFO]\t[TRAIN] Epoch=34/40, Step=2908/4124, loss=0.589305, time_each_step=0.31s, eta=2:12:45\n",
      "2021-05-06 11:01:28 [INFO]\t[TRAIN] Epoch=34/40, Step=3108/4124, loss=0.545137, time_each_step=0.3s, eta=2:11:42\n",
      "2021-05-06 11:02:29 [INFO]\t[TRAIN] Epoch=34/40, Step=3308/4124, loss=0.638202, time_each_step=0.3s, eta=2:10:42\n",
      "2021-05-06 11:03:30 [INFO]\t[TRAIN] Epoch=34/40, Step=3508/4124, loss=0.7568, time_each_step=0.31s, eta=2:9:44\n",
      "2021-05-06 11:04:31 [INFO]\t[TRAIN] Epoch=34/40, Step=3708/4124, loss=0.808842, time_each_step=0.3s, eta=2:8:40\n",
      "2021-05-06 11:05:31 [INFO]\t[TRAIN] Epoch=34/40, Step=3908/4124, loss=0.54667, time_each_step=0.3s, eta=2:7:39\n",
      "2021-05-06 11:06:32 [INFO]\t[TRAIN] Epoch=34/40, Step=4108/4124, loss=0.683838, time_each_step=0.3s, eta=2:6:38\n",
      "2021-05-06 11:06:37 [INFO]\t[TRAIN] Epoch 34 finished, loss=0.569941 .\n",
      "2021-05-06 11:06:37 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 11:06:44 [INFO]\t[EVAL] Finished, Epoch=34, miou=0.402102, category_iou=[0.42133966 0.57397874 0.42220182 0.19088647], oacc=0.584254, category_acc=[0.53349486 0.79456762 0.57295262 0.36588742], kappa=0.430431, category_F1-score=[0.59287681 0.72933481 0.59372983 0.32057879] .\n",
      "2021-05-06 11:06:48 [INFO]\tModel saved in output/deeplab/epoch_34.\n",
      "2021-05-06 11:06:48 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_26, miou=0.4932428532077531\n",
      "2021-05-06 11:07:47 [INFO]\t[TRAIN] Epoch=35/40, Step=184/4124, loss=0.286446, time_each_step=0.3s, eta=2:5:28\n",
      "2021-05-06 11:08:48 [INFO]\t[TRAIN] Epoch=35/40, Step=384/4124, loss=0.460445, time_each_step=0.3s, eta=2:4:32\n",
      "2021-05-06 11:09:49 [INFO]\t[TRAIN] Epoch=35/40, Step=584/4124, loss=0.367392, time_each_step=0.31s, eta=2:3:41\n",
      "2021-05-06 11:10:50 [INFO]\t[TRAIN] Epoch=35/40, Step=784/4124, loss=0.467704, time_each_step=0.31s, eta=2:2:41\n",
      "2021-05-06 11:11:51 [INFO]\t[TRAIN] Epoch=35/40, Step=984/4124, loss=0.396367, time_each_step=0.31s, eta=2:1:33\n",
      "2021-05-06 11:12:51 [INFO]\t[TRAIN] Epoch=35/40, Step=1184/4124, loss=0.56899, time_each_step=0.3s, eta=2:0:23\n",
      "2021-05-06 11:13:52 [INFO]\t[TRAIN] Epoch=35/40, Step=1384/4124, loss=0.587795, time_each_step=0.3s, eta=1:59:24\n",
      "2021-05-06 11:14:53 [INFO]\t[TRAIN] Epoch=35/40, Step=1584/4124, loss=0.767575, time_each_step=0.3s, eta=1:58:23\n",
      "2021-05-06 11:15:54 [INFO]\t[TRAIN] Epoch=35/40, Step=1784/4124, loss=0.510499, time_each_step=0.31s, eta=1:57:29\n",
      "2021-05-06 11:16:55 [INFO]\t[TRAIN] Epoch=35/40, Step=1984/4124, loss=0.603177, time_each_step=0.31s, eta=1:56:31\n",
      "2021-05-06 11:17:56 [INFO]\t[TRAIN] Epoch=35/40, Step=2184/4124, loss=0.699632, time_each_step=0.3s, eta=1:55:19\n",
      "2021-05-06 11:18:57 [INFO]\t[TRAIN] Epoch=35/40, Step=2384/4124, loss=0.51681, time_each_step=0.31s, eta=1:54:29\n",
      "2021-05-06 11:19:57 [INFO]\t[TRAIN] Epoch=35/40, Step=2584/4124, loss=0.695842, time_each_step=0.3s, eta=1:53:21\n",
      "2021-05-06 11:20:58 [INFO]\t[TRAIN] Epoch=35/40, Step=2784/4124, loss=0.693146, time_each_step=0.3s, eta=1:52:18\n",
      "2021-05-06 11:21:59 [INFO]\t[TRAIN] Epoch=35/40, Step=2984/4124, loss=0.425687, time_each_step=0.31s, eta=1:51:26\n",
      "2021-05-06 11:23:00 [INFO]\t[TRAIN] Epoch=35/40, Step=3184/4124, loss=0.377546, time_each_step=0.3s, eta=1:50:18\n",
      "2021-05-06 11:24:01 [INFO]\t[TRAIN] Epoch=35/40, Step=3384/4124, loss=0.469763, time_each_step=0.3s, eta=1:49:16\n",
      "2021-05-06 11:25:02 [INFO]\t[TRAIN] Epoch=35/40, Step=3584/4124, loss=0.854796, time_each_step=0.3s, eta=1:48:15\n",
      "2021-05-06 11:26:03 [INFO]\t[TRAIN] Epoch=35/40, Step=3784/4124, loss=0.606875, time_each_step=0.31s, eta=1:47:16\n",
      "2021-05-06 11:27:03 [INFO]\t[TRAIN] Epoch=35/40, Step=3984/4124, loss=0.523342, time_each_step=0.3s, eta=1:46:14\n",
      "2021-05-06 11:27:46 [INFO]\t[TRAIN] Epoch 35 finished, loss=0.557385 .\n",
      "2021-05-06 11:28:08 [INFO]\t[TRAIN] Epoch=36/40, Step=60/4124, loss=0.847363, time_each_step=0.3s, eta=1:45:1\n",
      "2021-05-06 11:29:09 [INFO]\t[TRAIN] Epoch=36/40, Step=260/4124, loss=0.438491, time_each_step=0.3s, eta=1:43:53\n",
      "2021-05-06 11:30:10 [INFO]\t[TRAIN] Epoch=36/40, Step=460/4124, loss=0.83676, time_each_step=0.3s, eta=1:42:59\n",
      "2021-05-06 11:31:11 [INFO]\t[TRAIN] Epoch=36/40, Step=660/4124, loss=0.418303, time_each_step=0.3s, eta=1:41:53\n",
      "2021-05-06 11:32:12 [INFO]\t[TRAIN] Epoch=36/40, Step=860/4124, loss=0.677716, time_each_step=0.3s, eta=1:40:49\n",
      "2021-05-06 11:33:12 [INFO]\t[TRAIN] Epoch=36/40, Step=1060/4124, loss=0.530869, time_each_step=0.3s, eta=1:39:46\n",
      "2021-05-06 11:34:13 [INFO]\t[TRAIN] Epoch=36/40, Step=1260/4124, loss=0.311912, time_each_step=0.3s, eta=1:38:50\n",
      "2021-05-06 11:35:14 [INFO]\t[TRAIN] Epoch=36/40, Step=1460/4124, loss=0.45848, time_each_step=0.3s, eta=1:37:51\n",
      "2021-05-06 11:36:14 [INFO]\t[TRAIN] Epoch=36/40, Step=1660/4124, loss=0.612108, time_each_step=0.3s, eta=1:36:51\n",
      "2021-05-06 11:37:15 [INFO]\t[TRAIN] Epoch=36/40, Step=1860/4124, loss=0.318378, time_each_step=0.3s, eta=1:35:48\n",
      "2021-05-06 11:38:16 [INFO]\t[TRAIN] Epoch=36/40, Step=2060/4124, loss=0.713158, time_each_step=0.31s, eta=1:34:59\n",
      "2021-05-06 11:39:17 [INFO]\t[TRAIN] Epoch=36/40, Step=2260/4124, loss=0.406478, time_each_step=0.3s, eta=1:33:49\n",
      "2021-05-06 11:40:18 [INFO]\t[TRAIN] Epoch=36/40, Step=2460/4124, loss=0.498093, time_each_step=0.3s, eta=1:32:47\n",
      "2021-05-06 11:41:18 [INFO]\t[TRAIN] Epoch=36/40, Step=2660/4124, loss=0.409713, time_each_step=0.3s, eta=1:31:49\n",
      "2021-05-06 11:42:19 [INFO]\t[TRAIN] Epoch=36/40, Step=2860/4124, loss=0.259084, time_each_step=0.3s, eta=1:30:43\n",
      "2021-05-06 11:43:21 [INFO]\t[TRAIN] Epoch=36/40, Step=3060/4124, loss=0.369554, time_each_step=0.31s, eta=1:29:54\n",
      "2021-05-06 11:44:21 [INFO]\t[TRAIN] Epoch=36/40, Step=3260/4124, loss=0.621772, time_each_step=0.31s, eta=1:28:47\n",
      "2021-05-06 11:45:23 [INFO]\t[TRAIN] Epoch=36/40, Step=3460/4124, loss=0.566693, time_each_step=0.3s, eta=1:27:45\n",
      "2021-05-06 11:46:23 [INFO]\t[TRAIN] Epoch=36/40, Step=3660/4124, loss=0.694113, time_each_step=0.3s, eta=1:26:44\n",
      "2021-05-06 11:47:24 [INFO]\t[TRAIN] Epoch=36/40, Step=3860/4124, loss=0.529701, time_each_step=0.3s, eta=1:25:43\n",
      "2021-05-06 11:48:25 [INFO]\t[TRAIN] Epoch=36/40, Step=4060/4124, loss=0.626586, time_each_step=0.3s, eta=1:24:42\n",
      "2021-05-06 11:48:44 [INFO]\t[TRAIN] Epoch 36 finished, loss=0.550263 .\n",
      "2021-05-06 11:48:44 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 11:48:51 [INFO]\t[EVAL] Finished, Epoch=36, miou=0.498456, category_iou=[0.48435636 0.70345939 0.49300916 0.31299875], oacc=0.672922, category_acc=[0.64155355 0.85793321 0.61340687 0.49892167], kappa=0.55515, category_F1-score=[0.65261466 0.82591859 0.66042349 0.4767693 ] .\n",
      "2021-05-06 11:48:55 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-05-06 11:48:59 [INFO]\tModel saved in output/deeplab/epoch_36.\n",
      "2021-05-06 11:48:59 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_36, miou=0.4984559141305472\n",
      "2021-05-06 11:49:44 [INFO]\t[TRAIN] Epoch=37/40, Step=136/4124, loss=0.554248, time_each_step=0.31s, eta=1:23:47\n",
      "2021-05-06 11:50:45 [INFO]\t[TRAIN] Epoch=37/40, Step=336/4124, loss=0.630592, time_each_step=0.3s, eta=1:22:27\n",
      "2021-05-06 11:51:46 [INFO]\t[TRAIN] Epoch=37/40, Step=536/4124, loss=0.435939, time_each_step=0.3s, eta=1:21:27\n",
      "2021-05-06 11:52:46 [INFO]\t[TRAIN] Epoch=37/40, Step=736/4124, loss=0.681599, time_each_step=0.3s, eta=1:20:37\n",
      "2021-05-06 11:53:47 [INFO]\t[TRAIN] Epoch=37/40, Step=936/4124, loss=0.545545, time_each_step=0.3s, eta=1:19:32\n",
      "2021-05-06 11:54:48 [INFO]\t[TRAIN] Epoch=37/40, Step=1136/4124, loss=0.585784, time_each_step=0.31s, eta=1:18:36\n",
      "2021-05-06 11:55:49 [INFO]\t[TRAIN] Epoch=37/40, Step=1336/4124, loss=0.284198, time_each_step=0.3s, eta=1:17:27\n",
      "2021-05-06 11:56:50 [INFO]\t[TRAIN] Epoch=37/40, Step=1536/4124, loss=0.393817, time_each_step=0.3s, eta=1:16:27\n",
      "2021-05-06 11:57:50 [INFO]\t[TRAIN] Epoch=37/40, Step=1736/4124, loss=0.390044, time_each_step=0.3s, eta=1:15:28\n",
      "2021-05-06 11:58:51 [INFO]\t[TRAIN] Epoch=37/40, Step=1936/4124, loss=0.292847, time_each_step=0.3s, eta=1:14:31\n",
      "2021-05-06 11:59:52 [INFO]\t[TRAIN] Epoch=37/40, Step=2136/4124, loss=0.661356, time_each_step=0.3s, eta=1:13:28\n",
      "2021-05-06 12:00:53 [INFO]\t[TRAIN] Epoch=37/40, Step=2336/4124, loss=0.535579, time_each_step=0.31s, eta=1:12:41\n",
      "2021-05-06 12:01:54 [INFO]\t[TRAIN] Epoch=37/40, Step=2536/4124, loss=0.734653, time_each_step=0.3s, eta=1:11:27\n",
      "2021-05-06 12:02:55 [INFO]\t[TRAIN] Epoch=37/40, Step=2736/4124, loss=0.393641, time_each_step=0.3s, eta=1:10:27\n",
      "2021-05-06 12:03:56 [INFO]\t[TRAIN] Epoch=37/40, Step=2936/4124, loss=0.489781, time_each_step=0.31s, eta=1:9:27\n",
      "2021-05-06 12:04:57 [INFO]\t[TRAIN] Epoch=37/40, Step=3136/4124, loss=0.592771, time_each_step=0.3s, eta=1:8:25\n",
      "2021-05-06 12:05:58 [INFO]\t[TRAIN] Epoch=37/40, Step=3336/4124, loss=0.437091, time_each_step=0.3s, eta=1:7:23\n",
      "2021-05-06 12:06:59 [INFO]\t[TRAIN] Epoch=37/40, Step=3536/4124, loss=0.724017, time_each_step=0.3s, eta=1:6:22\n",
      "2021-05-06 12:08:00 [INFO]\t[TRAIN] Epoch=37/40, Step=3736/4124, loss=0.434713, time_each_step=0.3s, eta=1:5:22\n",
      "2021-05-06 12:09:01 [INFO]\t[TRAIN] Epoch=37/40, Step=3936/4124, loss=0.524213, time_each_step=0.3s, eta=1:4:22\n",
      "2021-05-06 12:09:58 [INFO]\t[TRAIN] Epoch 37 finished, loss=0.538934 .\n",
      "2021-05-06 12:10:05 [INFO]\t[TRAIN] Epoch=38/40, Step=12/4124, loss=0.651293, time_each_step=0.5s, eta=1:16:59\n",
      "2021-05-06 12:11:07 [INFO]\t[TRAIN] Epoch=38/40, Step=212/4124, loss=0.380889, time_each_step=0.3s, eta=1:2:7\n",
      "2021-05-06 12:12:08 [INFO]\t[TRAIN] Epoch=38/40, Step=412/4124, loss=0.478307, time_each_step=0.3s, eta=1:1:11\n",
      "2021-05-06 12:13:08 [INFO]\t[TRAIN] Epoch=38/40, Step=612/4124, loss=0.362543, time_each_step=0.3s, eta=1:0:11\n",
      "2021-05-06 12:14:09 [INFO]\t[TRAIN] Epoch=38/40, Step=812/4124, loss=0.531644, time_each_step=0.31s, eta=0:59:17\n",
      "2021-05-06 12:15:10 [INFO]\t[TRAIN] Epoch=38/40, Step=1012/4124, loss=0.509224, time_each_step=0.31s, eta=0:58:19\n",
      "2021-05-06 12:16:10 [INFO]\t[TRAIN] Epoch=38/40, Step=1212/4124, loss=0.915589, time_each_step=0.31s, eta=0:57:23\n",
      "2021-05-06 12:17:11 [INFO]\t[TRAIN] Epoch=38/40, Step=1412/4124, loss=0.397236, time_each_step=0.3s, eta=0:56:10\n",
      "2021-05-06 12:18:12 [INFO]\t[TRAIN] Epoch=38/40, Step=1612/4124, loss=0.482921, time_each_step=0.3s, eta=0:55:8\n",
      "2021-05-06 12:19:13 [INFO]\t[TRAIN] Epoch=38/40, Step=1812/4124, loss=0.748888, time_each_step=0.3s, eta=0:54:6\n",
      "2021-05-06 12:20:14 [INFO]\t[TRAIN] Epoch=38/40, Step=2012/4124, loss=0.416834, time_each_step=0.3s, eta=0:53:6\n",
      "2021-05-06 12:21:15 [INFO]\t[TRAIN] Epoch=38/40, Step=2212/4124, loss=0.609766, time_each_step=0.3s, eta=0:52:9\n",
      "2021-05-06 12:22:16 [INFO]\t[TRAIN] Epoch=38/40, Step=2412/4124, loss=0.36977, time_each_step=0.3s, eta=0:51:1\n",
      "2021-05-06 12:23:16 [INFO]\t[TRAIN] Epoch=38/40, Step=2612/4124, loss=0.451139, time_each_step=0.31s, eta=0:50:9\n",
      "2021-05-06 12:24:18 [INFO]\t[TRAIN] Epoch=38/40, Step=2812/4124, loss=0.332688, time_each_step=0.31s, eta=0:49:13\n",
      "2021-05-06 12:25:19 [INFO]\t[TRAIN] Epoch=38/40, Step=3012/4124, loss=0.616112, time_each_step=0.31s, eta=0:48:12\n",
      "2021-05-06 12:26:19 [INFO]\t[TRAIN] Epoch=38/40, Step=3212/4124, loss=0.736805, time_each_step=0.3s, eta=0:47:4\n",
      "2021-05-06 12:27:20 [INFO]\t[TRAIN] Epoch=38/40, Step=3412/4124, loss=0.75054, time_each_step=0.3s, eta=0:46:4\n",
      "2021-05-06 12:28:21 [INFO]\t[TRAIN] Epoch=38/40, Step=3612/4124, loss=0.672796, time_each_step=0.3s, eta=0:45:2\n",
      "2021-05-06 12:29:22 [INFO]\t[TRAIN] Epoch=38/40, Step=3812/4124, loss=0.589423, time_each_step=0.3s, eta=0:44:1\n",
      "2021-05-06 12:30:23 [INFO]\t[TRAIN] Epoch=38/40, Step=4012/4124, loss=0.465459, time_each_step=0.3s, eta=0:43:0\n",
      "2021-05-06 12:30:57 [INFO]\t[TRAIN] Epoch 38 finished, loss=0.528084 .\n",
      "2021-05-06 12:30:57 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 12:31:04 [INFO]\t[EVAL] Finished, Epoch=38, miou=0.510421, category_iou=[0.52454689 0.70391077 0.49183056 0.32139632], oacc=0.695356, category_acc=[0.68280083 0.79610535 0.5844427  0.6497901 ], kappa=0.583336, category_F1-score=[0.6881348  0.82622962 0.65936518 0.48644954] .\n",
      "2021-05-06 12:31:08 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-05-06 12:31:11 [INFO]\tModel saved in output/deeplab/epoch_38.\n",
      "2021-05-06 12:31:11 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_38, miou=0.510421133024724\n",
      "2021-05-06 12:31:42 [INFO]\t[TRAIN] Epoch=39/40, Step=88/4124, loss=0.288298, time_each_step=0.3s, eta=0:41:44\n",
      "2021-05-06 12:32:43 [INFO]\t[TRAIN] Epoch=39/40, Step=288/4124, loss=0.290946, time_each_step=0.31s, eta=0:40:43\n",
      "2021-05-06 12:33:44 [INFO]\t[TRAIN] Epoch=39/40, Step=488/4124, loss=0.613046, time_each_step=0.31s, eta=0:39:52\n",
      "2021-05-06 12:34:44 [INFO]\t[TRAIN] Epoch=39/40, Step=688/4124, loss=0.853886, time_each_step=0.3s, eta=0:38:38\n",
      "2021-05-06 12:35:45 [INFO]\t[TRAIN] Epoch=39/40, Step=888/4124, loss=0.511322, time_each_step=0.3s, eta=0:37:27\n",
      "2021-05-06 12:36:46 [INFO]\t[TRAIN] Epoch=39/40, Step=1088/4124, loss=0.485847, time_each_step=0.31s, eta=0:36:57\n",
      "2021-05-06 12:37:47 [INFO]\t[TRAIN] Epoch=39/40, Step=1288/4124, loss=0.45785, time_each_step=0.32s, eta=0:36:10\n",
      "2021-05-06 12:38:48 [INFO]\t[TRAIN] Epoch=39/40, Step=1488/4124, loss=0.686554, time_each_step=0.3s, eta=0:34:33\n",
      "2021-05-06 12:39:49 [INFO]\t[TRAIN] Epoch=39/40, Step=1688/4124, loss=0.533588, time_each_step=0.31s, eta=0:33:44\n",
      "2021-05-06 12:40:50 [INFO]\t[TRAIN] Epoch=39/40, Step=1888/4124, loss=0.660068, time_each_step=0.3s, eta=0:32:33\n",
      "2021-05-06 12:41:51 [INFO]\t[TRAIN] Epoch=39/40, Step=2088/4124, loss=0.375769, time_each_step=0.3s, eta=0:31:31\n",
      "2021-05-06 12:42:51 [INFO]\t[TRAIN] Epoch=39/40, Step=2288/4124, loss=0.295521, time_each_step=0.31s, eta=0:30:39\n",
      "2021-05-06 12:43:52 [INFO]\t[TRAIN] Epoch=39/40, Step=2488/4124, loss=1.001956, time_each_step=0.3s, eta=0:29:28\n",
      "2021-05-06 12:44:53 [INFO]\t[TRAIN] Epoch=39/40, Step=2688/4124, loss=0.481216, time_each_step=0.31s, eta=0:28:37\n",
      "2021-05-06 12:45:54 [INFO]\t[TRAIN] Epoch=39/40, Step=2888/4124, loss=0.445678, time_each_step=0.3s, eta=0:27:29\n",
      "2021-05-06 12:46:54 [INFO]\t[TRAIN] Epoch=39/40, Step=3088/4124, loss=0.33942, time_each_step=0.31s, eta=0:26:34\n",
      "2021-05-06 12:47:55 [INFO]\t[TRAIN] Epoch=39/40, Step=3288/4124, loss=0.545912, time_each_step=0.31s, eta=0:25:28\n",
      "2021-05-06 12:48:56 [INFO]\t[TRAIN] Epoch=39/40, Step=3488/4124, loss=0.472506, time_each_step=0.31s, eta=0:24:29\n",
      "2021-05-06 12:49:57 [INFO]\t[TRAIN] Epoch=39/40, Step=3688/4124, loss=0.443512, time_each_step=0.3s, eta=0:23:26\n",
      "2021-05-06 12:50:58 [INFO]\t[TRAIN] Epoch=39/40, Step=3888/4124, loss=0.211118, time_each_step=0.3s, eta=0:22:25\n",
      "2021-05-06 12:51:59 [INFO]\t[TRAIN] Epoch=39/40, Step=4088/4124, loss=0.344094, time_each_step=0.3s, eta=0:21:24\n",
      "2021-05-06 12:52:09 [INFO]\t[TRAIN] Epoch 39 finished, loss=0.52023 .\n",
      "2021-05-06 12:53:04 [INFO]\t[TRAIN] Epoch=40/40, Step=164/4124, loss=0.745202, time_each_step=0.31s, eta=0:20:26\n",
      "2021-05-06 12:54:05 [INFO]\t[TRAIN] Epoch=40/40, Step=364/4124, loss=0.479496, time_each_step=0.3s, eta=0:19:16\n",
      "2021-05-06 12:55:06 [INFO]\t[TRAIN] Epoch=40/40, Step=564/4124, loss=0.583424, time_each_step=0.3s, eta=0:18:8\n",
      "2021-05-06 12:56:06 [INFO]\t[TRAIN] Epoch=40/40, Step=764/4124, loss=0.338651, time_each_step=0.31s, eta=0:17:19\n",
      "2021-05-06 12:57:07 [INFO]\t[TRAIN] Epoch=40/40, Step=964/4124, loss=0.255538, time_each_step=0.3s, eta=0:16:11\n",
      "2021-05-06 12:58:08 [INFO]\t[TRAIN] Epoch=40/40, Step=1164/4124, loss=0.683865, time_each_step=0.31s, eta=0:15:19\n",
      "2021-05-06 12:59:09 [INFO]\t[TRAIN] Epoch=40/40, Step=1364/4124, loss=0.490217, time_each_step=0.3s, eta=0:14:11\n",
      "2021-05-06 13:00:10 [INFO]\t[TRAIN] Epoch=40/40, Step=1564/4124, loss=0.332674, time_each_step=0.3s, eta=0:13:7\n",
      "2021-05-06 13:01:11 [INFO]\t[TRAIN] Epoch=40/40, Step=1764/4124, loss=0.40117, time_each_step=0.3s, eta=0:12:14\n",
      "2021-05-06 13:02:11 [INFO]\t[TRAIN] Epoch=40/40, Step=1964/4124, loss=0.317487, time_each_step=0.3s, eta=0:11:4\n",
      "2021-05-06 13:03:12 [INFO]\t[TRAIN] Epoch=40/40, Step=2164/4124, loss=0.563504, time_each_step=0.3s, eta=0:10:12\n",
      "2021-05-06 13:04:13 [INFO]\t[TRAIN] Epoch=40/40, Step=2364/4124, loss=0.258949, time_each_step=0.3s, eta=0:9:8\n",
      "2021-05-06 13:05:14 [INFO]\t[TRAIN] Epoch=40/40, Step=2564/4124, loss=0.331187, time_each_step=0.3s, eta=0:8:7\n",
      "2021-05-06 13:06:14 [INFO]\t[TRAIN] Epoch=40/40, Step=2764/4124, loss=0.542227, time_each_step=0.3s, eta=0:7:4\n",
      "2021-05-06 13:07:15 [INFO]\t[TRAIN] Epoch=40/40, Step=2964/4124, loss=0.617387, time_each_step=0.3s, eta=0:6:2\n",
      "2021-05-06 13:08:16 [INFO]\t[TRAIN] Epoch=40/40, Step=3164/4124, loss=0.526707, time_each_step=0.3s, eta=0:5:5\n",
      "2021-05-06 13:09:17 [INFO]\t[TRAIN] Epoch=40/40, Step=3364/4124, loss=0.365702, time_each_step=0.3s, eta=0:4:5\n",
      "2021-05-06 13:10:18 [INFO]\t[TRAIN] Epoch=40/40, Step=3564/4124, loss=0.422816, time_each_step=0.3s, eta=0:3:4\n",
      "2021-05-06 13:11:19 [INFO]\t[TRAIN] Epoch=40/40, Step=3764/4124, loss=0.405796, time_each_step=0.3s, eta=0:2:3\n",
      "2021-05-06 13:12:20 [INFO]\t[TRAIN] Epoch=40/40, Step=3964/4124, loss=0.412118, time_each_step=0.31s, eta=0:1:4\n",
      "2021-05-06 13:13:08 [INFO]\t[TRAIN] Epoch 40 finished, loss=0.510186 .\n",
      "2021-05-06 13:13:08 [INFO]\tStart to evaluating(total_samples=666, total_steps=42)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:07<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 13:13:15 [INFO]\t[EVAL] Finished, Epoch=40, miou=0.497667, category_iou=[0.53342848 0.67420472 0.46010928 0.32292643], oacc=0.682026, category_acc=[0.65099894 0.79667228 0.66992486 0.53847685], kappa=0.562318, category_F1-score=[0.69573311 0.80540296 0.63023952 0.48820014] .\n",
      "2021-05-06 13:13:18 [INFO]\tModel saved in output/deeplab/epoch_40.\n",
      "2021-05-06 13:13:18 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_38, miou=0.510421133024724\n"
     ]
    }
   ],
   "source": [
    "num_classes_1 = len(train_dataset.labels)\r\n",
    "regularizer_1=fluid.regularizer.L2DecayRegularizer(regularization_coeff=0.3)\r\n",
    "# model=pdx.seg.HRNet(num_classes=num_classes_1, width=32)\r\n",
    "model = pdx.seg.DeepLabv3p(\r\n",
    "    num_classes=num_classes_1,  backbone='Xception65'\r\n",
    ")\r\n",
    "\r\n",
    "\r\n",
    "#file = open('./weights.txt', 'w')\r\n",
    "# for v in model.trainable_variables:\r\n",
    "#     file.write(str(v.name) + '\\n')\r\n",
    "#     file.write(str(v.shape) + '\\n')\r\n",
    "#     file.write(str(v.numpy()) + '\\n')\r\n",
    "# file.close()\r\n",
    "model.train(\r\n",
    "    num_epochs=40,  # 训练迭代轮数\r\n",
    "    train_dataset=train_dataset,  # 训练数据读取器\r\n",
    "    train_batch_size=16,  #训练数据batch大小，同时作为验证数据batch大小。默认32\r\n",
    "    eval_dataset=eval_dataset,  # 评估数据读取器\r\n",
    "    save_interval_epochs=2,  # 模型保存间隔，默认1\r\n",
    "    log_interval_steps=200,  # 训练日志输出间隔，默认2\r\n",
    "    save_dir='output/deeplab',  # 模型保存路径\r\n",
    "    pretrain_weights='COCO',\r\n",
    "    # optimizer = fluid.optimizer.Adam(learning_rate=4e-4, beta1=0.9, beta2=0.95,regularization=regularizer_1),\r\n",
    "    # optimizer = fluid.optimizer.Adam(learning_rate=5e-4, beta1=0.9, beta2=0.95),\r\n",
    "    optimizer = fluid.optimizer.MomentumOptimizer(learning_rate=3e-3, momentum=0.91, use_nesterov=True),\r\n",
    "    lr_decay_power=0.925,\r\n",
    "    use_vdl=True,\r\n",
    "    #sensitivities_file='DEFAULT',\r\n",
    "    eval_metric_loss=0.002,\r\n",
    "    early_stop=True,\r\n",
    "    early_stop_patience=4\r\n",
    "    #resume_checkpoint='weights.txt'\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 13:13:18 [INFO]\tStart to evaluating(total_samples=666, total_steps=666)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 666/666 [00:11<00:00, 55.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('miou', 0.4976673934748348),\n",
       "             ('category_iou',\n",
       "              array([0.53342848, 0.67420472, 0.46010952, 0.32292685])),\n",
       "             ('oacc', 0.6820258281298639),\n",
       "             ('category_acc',\n",
       "              array([0.65099894, 0.79667228, 0.66992536, 0.53847717])),\n",
       "             ('kappa', 0.5623185568700259),\n",
       "             ('category_F1-score',\n",
       "              array([0.69573311, 0.80540296, 0.63023974, 0.48820061]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(eval_dataset, batch_size=1, epoch_id=None, return_details=False)\r\n",
    "# eval_dataset (paddlex.datasets): 评估数据读取器。\r\n",
    "# batch_size (int): 评估时的batch大小。默认1。\r\n",
    "# epoch_id (int): 当前评估模型所在的训练轮数。\r\n",
    "# return_details (bool): 是否返回详细信息。默认False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/xception.py:316\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 13:13:34 [INFO]\tModel[DeepLabv3p] loaded.\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\r\n",
    "model = pdx.load_model('./output/deeplab/best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [01:12<00:00, 63.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # tqdm 是一个快速，可扩展的Python进度条，可以在 Python 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器 tqdm(iterator)。\r\n",
    "import cv2\r\n",
    "\r\n",
    "test_base = 'img_testA/'\r\n",
    "out_base = 'ccf_baidu_remote_sense/result/'\r\n",
    "\r\n",
    "if not os.path.exists(out_base):  # 判断out_base的路径是否存在\r\n",
    "    os.makedirs(out_base)  # os.makedirs() 方法用于递归创建目录\r\n",
    "\r\n",
    "\r\n",
    "for im in tqdm(os.listdir(test_base)):  # os.listdir()返回path指定的文件夹包含的文件或文件夹的名字的列表\r\n",
    "    if not im.endswith('.jpg'):  # 判断文件名后缀\r\n",
    "        continue\r\n",
    "    pt = test_base + im\r\n",
    "    #result = model.overlap_tile_predict(pt, tile_size=[512, 512], pad_size=[64, 64], batch_size=32, transforms=eval_transforms)\r\n",
    "    result = model.predict(pt)  # 使用训练好的模型\r\n",
    "    cv2.imwrite(out_base+im.replace('jpg', 'png'), result['label_map'])  #  cv2.imwrite()保存图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
